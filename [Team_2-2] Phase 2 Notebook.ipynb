{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f60f6794-b509-44c6-b3bc-0a78d894b6f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Cleared for Takeoff:** _Moderate to Severe Flight Delay Classification_\n",
    "### Team 2-2\n",
    "Daniel Costa (daniel_costa@berkeley.edu)<br>\n",
    "Ryan Farhat-Sabet (ryan_farhat-sabet@berkeley.edu)<br>\n",
    "Ankush Garg (ankush-garg@berkeley.edu) <br>\n",
    "Maia Kennedy (maia_kennedy@berkeley.edu)<br>\n",
    "Stephanie Owyang (seowyang@berkeley.edu)<br><br>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/team_picture.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f41df99-17d7-407e-b8b2-9e42c5320ae5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Phase Leader Plan\n",
    "\n",
    "| Week | Leader | \n",
    "| :--- | :--- | \n",
    "| 10/27 (Phase 1) | Stephanie Owyang | \n",
    "| 11/3 | Daniel Costa|\n",
    "| 11/10 (Fall Break) | Ankush Garg| \n",
    "| 11/17 (Phase 2) | Ankush Garg| \n",
    "| 11/24 (Thanksgiving Break)| Maia Kennedy|\n",
    "| 12/1 | Ryan Farhat-Sabet|\n",
    "| 12/8 (Phase 3) | Daniel Costa | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cda683b-ceb6-4818-8144-5dc4cc9fbdee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Phase 2: Credit Assignment Plan - Team Member View\n",
    "\n",
    "| **Team Member** | **Task** | **Est. Hours** |\n",
    "| :--- | :--- | :--- |\n",
    "| **Ankush Garg** | Evolve Phase 1 abstract for Phase 2 | 0.5 |\n",
    "| | Develop code for train/val/test splits | 2 |\n",
    "| | Develop code for CV splits and CV (3M and 1Year) | 10 |\n",
    "| | Develop code for MLFlow integration with Databricks | 2 |\n",
    "| | Co-develop code (with Stephanie) for Baseline model generation, feature engineering (3 features) | 3 |\n",
    "| | Co-develop code (with Stephanie) for hyperparameter-tuning | 3 |\n",
    "| | CV and hyperparameter-tuning write-up | 1 |\n",
    "| | Prepare feature engineering + training/validation results slides for phase 2 presentation | 1 |\n",
    "| | Project planning | 1 |\n",
    "| | **Subtotal** | **23.5** |\n",
    "| **Daniel Costa** | Project Description<br>EDA Support | 7 - 10 |\n",
    "| | Slide prep/visualizatoins for presentation | 3 |\n",
    "| | Custom Join EDA, Implementation and Write-Up | 20 |\n",
    "| | Results Parsing and Write-Up | 3 |\n",
    "| | **Subtotal** | **26** |\n",
    "| **Ryan Farhat-Sabet** | EDA Lead | 12 |\n",
    "| | Slide prep for presentation | 2 |\n",
    "| | Write-up for report | 4 |\n",
    "| | **Subtotal** | **16** |\n",
    "| **Maia Kennedy** | Developed code for feature engineering (3 features) | 2.5 |\n",
    "| | Debug and co-develop code (with Stephanie) for baseline LR hyperparameter-tuning | 3 |\n",
    "| | Create error analysis pipeline for future evaluation | 3 |\n",
    "| | Analyze the error patterns of in-progress model(s) to identify systematic weaknesses and generate evidence-based hypotheses for potential improvement areas | 3 |\n",
    "| | Prepare overall team slide template and organize flow for FP2 presentation | 3 |\n",
    "| | Prepare error analysis and pipeline slides for phase 2 presentation | 1 |\n",
    "| | Author conclusion and co-author results & discussion (with Stephanie / Daniel) for report |2.5 |\n",
    "| | Project planning & report QA | 3 |\n",
    "| | **Subtotal** | **21** |\n",
    "| **Stephanie Owyang** | Developed code for feature engineering (4 features) | 3 |\n",
    "| | Co-develop code (with Ankush) for Baseline model generation | 2 |\n",
    "| | Integrate all engineered features into baseline model experiements | 4 |\n",
    "| | Co-develop code (with Ankush and Maia) for hyperparameter-tuning | 8 |\n",
    "| | Prepared slides for feature selection and baseline model for phase 2 presentation | 2 |\n",
    "| | Feature selection and Feature engineering write-up | 2 |\n",
    "| | (Feature Selection) Baseline model experimentation write-up | 1 |\n",
    "| | **Subtotal** | **22** |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "993f01f0-0ce9-4098-a47e-5d61c2f550ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Abstract\n",
    "The aviation industry faces immense operational and financial costs from flight delays, with cascading effects on crew scheduling, crew/airplane management, and passenger connections. This project develops a model to predict flight delays of 15 minutes or more within a 2 hours prediction window, enabling proactive operational adjustments by airline operators. We utilize a custom-joined dataset, combining a flights dataset from the Department of Transportation (DOT) and Weather dataset from National Oceanic and Atmospheric Administration (NOAA). Our exploratory analysis revealed significant class imbalance, with only 18.29% of flights experiencing delays of 15 minutes or more, necessitating careful consideration of both precision and recall in our evaluation approach.\n",
    "\n",
    "Our baseline model, an XGBoost Regressor, trained on engineered features, selected through rigorous sliding-window cross-validation across multiple hyperparameter configurations. The optimal model achieved a validation MAE of 12.45 minutes and a test MAE of 14.32 minutes. When applying a 15 minute threshold for binary classification, the model achieves a precision of 0.45, recall of 0.56, and F2 score of 0.54 on the test set.\n",
    "Key engineered features driving performance include weather imputation using a custom join, aircraft daily workload tracking, turnaround time calculations, and temporal features capturing the time difference between incoming flight arrival and next scheduled departure.\n",
    "\n",
    "Next steps include feeding this continuous delay signal into a Random Forest Classifier to generate a refined binary prediction for operations decision-making. We will also explore advanced graph-based features capturing airport connectivity patterns and implement the client-requested Multilayer Perceptron architecture to establish the optimal production-ready pipeline, with all the approaches benchmarked against our current baseline performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd91e83f-4f41-4d66-bd8c-1877e16c54c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Project Description\n",
    "\n",
    "Our core objective is to accurately predict flight delays in a way that directly supports airline operators and air traffic controllers. To accomplish this, we adopt a two-model strategy. This report focuses on the first component: a regression model that produces a continuous delay estimate using data available up to two hours before departure. In future iterations, a downstream classification model will use this output to determine whether a flight is likely to be delayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23505007-7126-4736-b259-0accfd5bc6a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Data Description\n",
    "We began by reviewing the three primary datasets and their supporting auxiliary sources: (1) a comprehensive U.S. passenger flight dataset, (2) an airport reference dataset containing airport codes and locations, (3) a detailed weather dataset with observations recorded at specific stations and times, and (4) a companion weather-station dataset providing station locations. We also considered an existing combined flight–weather dataset (OPTW), but because its construction methodology is unknown, we will not use it or report on it. Instead, we will create our own custom, transparent flight-weather join tailored to the needs of this project.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Flight Dataset\n",
    "    - source: [Department of Transportation (DOT)](https://www.transtats.bts.gov/Tables.asp?QO_VQ=EFD&QO_anzr=Nv4yv0r%FDb0-gvzr%FDcr4s14zn0pr%FDQn6n&QO_fu146_anzr=b0-gvzr)\n",
    "    - size (3-month dataset): 1,403,471 x 109 (0.09GB)\n",
    "    - size (1-year dataset): 7,422,037 x 109 (0.58GB)\n",
    "- Airport Codes Dataset\n",
    "    - source: [Department of Transportation (DOT)](https://datahub.io/core/airport-codes)\n",
    "    - size: 57,421 x 12 (0.01GB)\n",
    "\n",
    "- Weather Dataset\n",
    "    - source: [National Oceanic and Atmospheric Administration repository (NOAA)](https://www.ncei.noaa.gov/pub/data/cdo/documentation/LCD_documentation.pdf)\n",
    "    - size (3-month dataset): 30,528,602 x 124 (1.09GB)\n",
    "    - size (1-year dataset): 131,937,550 x 124 (4.73GB)\n",
    "\n",
    "- Weather Station Dataset\n",
    "    - size: 5,004,169 x 12 (0.05GB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06b08732-2b89-4e38-858d-2e6c693de254",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/phase2_eda_images/ph2_flights_null_1y.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2e9c310-5e6c-4002-bd9f-bc2e15ab1e27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "We performed this analysis on the 3-month data first before expanding it to the 1-year data. We have just included charts for the 1-year data below to not be too verbose here. For a full data dictionary of all features for each dataset and the 3-month charts, please refer to the EDA notebook in the appendix.\n",
    "\n",
    "#### Flights Dataset\n",
    "\n",
    "Looking first at the flight data, the dataset itself comes from the Department of Transportation. It has a lot of flight metadata, including date and time information, departure/arrival airport and location data, airline information, and flight route status and timing, all of which we will likely use. To call out a few specific ones that looked particularly interesting:\n",
    "- `FL_DATE` (date of the flight) and other date variables (`QUARTER`, `MONTH`, `DAY_OF_MONTH`, `DAY_OF_WEEK`)\n",
    "- `OP_CARRIER` (flight airline carrier)\n",
    "- `ORIGIN/DEST_AIRPORT` (airport each flight flew out of and landed into)\n",
    "- `DEP_TIME` (time of flight departure)\n",
    "- `DISTANCE` (flight route distance)\n",
    "\n",
    "As far as completeness of this dataset, we noticed the data was duplicated, so we first had to drop all duplicates. We then had to decide on a unique key to identify each flight, so we landed (no pun intended) on the combination of flight date, airline, flight number, and origin airport (some flights will have the same flight number on the same day if the aircraft is continuing to a different destination, so that origin airport part is crucial for uniqueness). All of the above-mentioned features have very few nulls, as do most of the flight metadata around takeoff and landing, including if a flight was delayed and for how long. Many of the fields having to do with when a flight was diverted are haphazardly populated at best because so few flights are diverted, so we decided to ignore those fields. Cause of delay fields also have many nulls, but this is because not all flights are delayed, so we can impute these values with zeros.\n",
    "<br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/phase2_eda_images/ph2_flights_null_1y.png\">\n",
    "\n",
    "We did take a look at flight patterns over the course of the year, and we could see that most airlines seemed to run flights along similar schedules, with one day a week consistently seeing fewer flights. It's pretty much a given that date is going to be an important variable for predicting delays given that flight volume changes throughout the year, but day of week seems likely to be an important predictor as well.\n",
    "<br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/phase2_eda_images/ph2_flights_time_series_1y.png\">\n",
    "<br><br>\n",
    "\n",
    "#### Airports Dataset\n",
    "\n",
    "Since the airport code dataset itself is mainly supplemental, we really only need enough data to join it to the flight data, so identity code and name should be enough. Before we joined it to the flight data, we examine it as its own dataset. There are 57,421 airports in the dataset itself. Some other identity-related fields have lots of nulls, but of those features with no or few nulls, the important ones we found interesting were:\n",
    "- Coordinates\n",
    "- Type (ex: `small_airport`, `medium_airport`, `large_airport`)\n",
    "- Elevation\n",
    "\n",
    "All airports have coded coordinates and type, and most open passenger airports have elevation, so no data deletion will be necessary here.\n",
    "<br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/phase2_eda_images/ph2_airports_nulls.png\">\n",
    "\n",
    "We can also see the distribution of the types of airports represented in this dataset in the chart below. As we can see, small airports account for more than half of the airports in the dataset:\n",
    "<br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/phase2_eda_images/ph2_airports_types.png\">\n",
    "\n",
    "The dataset itself has more than just US airports, so once we filtered it down, we could then join it together with the 1-year flights data to visualize more trends. We first looked at the number of flights, delayed and not delayed, by airport type, and we noticed that most flights were flying out of large airports, but of those that were delayed, more of those delayed flights flew out of large airports compared to medium airports (19% vs 16%). Airport size could be an important variable to use in our prediction model.\n",
    "<br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/phase2_eda_images/ph2_flights_airport_types_1y.png\">\n",
    "\n",
    "We then looked at the number of flights by airport itself. We saw that a few airports see the most flights in the country, and they are mostly concentrated around major metropolitan areas. We imagine larger flight volume means more opportunities for delays, so this could be another important variable we could use later on.\n",
    "<br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/phase2_eda_images/ph2_flights_top_airports_1y.png\">\n",
    "<br><br>\n",
    "\n",
    "#### Weather Dataset\n",
    "\n",
    "Moving on to the weather and weather station data, the data is taken from the National Centers for Environmental Information, and it is the messiest of the bunch. We first realized this data was not limited to just the US, so we had to narrow down the data ourselves. We then identified a whole host of features we liked to potentially include:\n",
    "- Hourly data (wind speed, wind direction, dry bulb temp, relative humidity, visibility, sky conditions, precipitation)\n",
    "- Daily and Monthly data (temperature max/min/avg, sunrise/sunset, weather, snow, precipitation, wind)\n",
    "\n",
    "As far as completeness of this dataset, there is a lot of null data. A lot of this stems from the features themselves and how each datapoint is recorded. Each line is a point in time, so it could be the weather report at a very specific minute, whereas a lot of the data, especially a lot of the null data, is at the daily/monthly level. We should be able to impute and copy some of the daily/monthly metrics into the hourly data to fill in some of the nulls there. The hourly data that is null mainly stems from specific weather patterns that aren't always present, like precipitation, so we should be able to impute zero values for some of those variables.\n",
    "<br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/phase2_eda_images/ph2_weather_nulls_1y_.png\">\n",
    "\n",
    "Not all stations report in equal time increments as well. The below chart showcases this very well, as we can see spikes in reporting each day as most stations will at least have one daily report, and we can see a super spike each month as almost all stations report at least one report a month. It is interday that we get variation in how often each station reports. Since we will be doing our own custom join of the weather data with the flight data, we have a strategy to capture the most accurate weather reading at the time of each flight, but we will get to that in a moment.\n",
    "<br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/phase2_eda_images/ph2_daily_weather_1y.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1218d81-e13a-4dca-a2e4-41ffb52b7183",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Custom Join\n",
    "\n",
    "#### Weather–Flight Data Integration and Spatial Imputation\n",
    "\n",
    "To enrich each flight record with localized weather conditions, we constructed a custom spatial–temporal join between multiple data sources. The workflow incorporated data cleaning, feature engineering, spatial proximity modeling, and a streamlined Kriging-based imputation strategy.\n",
    "\n",
    "#### Data Ingestion and Preprocessing\n",
    "\n",
    "We began by ingesting the flights dataset, removing duplicate records, and constructing a unique `flight_id` derived from flight attributes. The weather and station datasets were then ingested and cleaned. From the raw NOAA hourly observations, we...\n",
    "\n",
    "- Parsed the `HourlySkyConditions` field to extract numerical oktas (cloud cover) and cloud layer elevation.  \n",
    "- Transformed `HourlyWindSpeed` and `HourlyWindDirection` into orthogonal northward and eastward components, enabling linear imputation. \n",
    "- Retained only weather features with at least **80% non-null coverage** to ensure reliability.\n",
    "\n",
    "#### Spatial Mapping Between Airports and Weather Stations\n",
    "\n",
    "We then established spatial relationships between airports and nearby weather stations. Using latitude–longitude coordinates and the haversine distance formula, we identified all stations within a **50 km radius** of each airport, consistent with methods used by the [FAA](https://www.faa.gov/documentLibrary/media/Advisory_Circular/AC_150_5220-16E_w-chg1.pdf). These distances formed the basis for computing spatial interpolation weights.\n",
    "\n",
    "To approximate a Kriging system, we solved for spatial coefficients using these pairwise distances and normalized the final weights so that they summed to 1 for each airport, reflecting each station’s relative influence.\n",
    "\n",
    "#### Temporal Alignment and Time-Zone Normalization\n",
    "\n",
    "Because airports and their neighboring weather stations may span multiple time zones, all timestamps in both the flight and weather datasets were converted to GMT. This ensured that temporal joins were consistent across locations.\n",
    "\n",
    "#### Weather–Flight Join and Multi-Stage Aggregation\n",
    "\n",
    "The integration proceeded in several stages:\n",
    "\n",
    "1. **Airport–Station Association:**  \n",
    "   Joined each flight to its airport’s set of neighboring stations and precomputed spatial weights.\n",
    "\n",
    "2. **Weather Association:**  \n",
    "   Merged hourly weather readings by matching station IDs and filtering to observations between **2 and 12 hours prior to departure**. The lower bound is a constraint of this assignment, and the upper bound is supported by [weather imputation literature from the FAA](https://www.faa.gov/documentLibrary/media/Advisory_Circular/AC_150_5220-16E_w-chg1.pdf).\n",
    "\n",
    "3. **Temporal Aggregation:**  \n",
    "   For each station, aggregated weather measurements across the time window, normalizing by the number of non-null readings to avoid overweighting sparse data.\n",
    "\n",
    "4. **Spatial Imputation:**  \n",
    "   Computed a dot product between the station-level aggregated weather vectors and the station weights for that airport to generate the final imputed weather features.\n",
    "\n",
    "#### Computational Shortcut and Edge-Case Handling\n",
    "\n",
    "A practical challenge arises when a neighboring station lacks valid readings in the 2–12 hour window. In such cases the original Kriging weights, computed under the assumption of complete station availability, no longer apply. Recomputing weights dynamically for each flight would drastically increase runtime.\n",
    "\n",
    "To address this, we adopted a computational shortcut:  \n",
    "**renormalize the spatial weights over only the stations with available readings**, preserving their relative influence without re-solving the Kriging system.\n",
    "\n",
    "Across the 5-year dataset of **41.45 million flights**, only **34 flights** fell into a scenario where all stations with high positive weights lacked readings while mostly small negative-weight stations remained. Under this shortcut, these cases produced unrealistic imputed values (e.g., temperatures exceeding thousands of degrees Fahrenheit).\n",
    "\n",
    "To ensure physical plausibility, **all imputed weather values were clipped to the observed minimum and maximum ranges** found in the original weather dataset.\n",
    "\n",
    "Below is a summary of the join runs for all datasets:\n",
    "\n",
    "| Dataset | Number of Flights     | Join Runtime (m) | % Flights with 1+ Non-Null Readings | Parquet Filesize |\n",
    "|---------|---------------|----------|------------|---------|\n",
    "| 3 months      | 1,356,814     | 6.29 | 99.9967    | 215MB   |\n",
    "| 6 months      | 2,818,553     | 8.91      | 99.9981    | 460MB   |\n",
    "| 1 year     | 7,268,230     | 16.61    | 99.9965    | 1.082GB |\n",
    "| 5 years     | 41,449,407    | 187.73   | 99.9984    | 6.173GB  |\n",
    "\n",
    "#### Final Joined EDA\n",
    "\n",
    "With all our data joined now, we can do a final round of EDA. We're once again only including charts for the 1-year data below. We can see the final dimensions of our joined cleaned dataset are 7,291,950 x 121. We can also see that most of the hourly weather data we've attached to each flight is filled in and not null, so our custom join has helped to provide important supplementary data on each flight!\n",
    "<br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/phase2_eda_images/ph2_joined_nulls.png\">\n",
    "\n",
    "We can also run an additional version of our top flights by airport chart for delayed flights specifically, and we see a similar trend as before, with most delayed flights originating from large metropolitan areas.\n",
    "<br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/phase2_eda_images/ph2_joined_top_airports_delayed.png\">\n",
    "\n",
    "Let's look at a few new graphs, starting with a chart of the number of delayed flights by hour of each day, split out by airline. We can see a clear trend where delays pile up as each day goes on, starting with some delays in the morning and growing more and more until it reaches a peak in the early evening, before dropping rapidly as the night goes on. We can also see a few standout airlines with quite a few delays, Southwest and American being the most noticeable. Both this time component and airline itself are likely to be important variables to include in our model.\n",
    "<br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/phase2_eda_images/ph2_joined_delayed_flights_by_hour.png\">\n",
    "\n",
    "We also wanted to look at the average daily delay rate over the course of the year, and while there weren't any obvious patterns, we can definitely see that there are times of the year when there are spikes or sustained spikes in delay rates that would be important for our model to consider.\n",
    "<br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/phase2_eda_images/ph2_joined_average_daily_delay_rate.png\">\n",
    "\n",
    "Finally, we had to do a gut check and look at all of our continuous variables to make sure we were accounting for any highly correlated variables. We could see very high correlation between the elapsed time, air time, and distance variables, so we wouldn't have use for all of them in our final model. Arrival delay and departure delay were also highly correlated, unsurprisingly, as a departure delay is almost certain to cause an arrival delay. Both arrival and departure delay were somewhat correlated to carrier and late aircraft delays, which made sense, but was still important to account for nonetheless. Lastly, the weather features had a bit more interaction amongst each other, most notably as wet bulb, dry bulb, and dew point temperature were all highly correlated. Once again, this is something we could keep an eye on as we tested features for our final model.\n",
    "<br><br>\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/phase2_eda_images/ph2_joined_corr_matrix.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3135a509-af9c-4de5-aa65-269852fc87ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Machine Learning Pipeline\n",
    "\n",
    "#### Pipeline Overview\n",
    "The figure below illustrates the end-to-end machine learning pipeline we will implement for our flight delay prediction system. The design follows Databricks’ modular workflows emphasizing reproducibility, efficiency, and operational realism. Each stage of the pipeline introduces formal checkpoints to ensure data integrity, model traceability, and temporal consistency throughout the experimentation and deployment lifecycle.\n",
    "\n",
    "The data ingestion stage consolidates multiple raw data sources into unified, high-performance Parquet tables. Converting CSVs into Parquet format improves I/O performance, reduces storage overhead, and optimizes large-scale joins required for feature enrichment. The ingestion stage produces a single, time-indexed dataset representing all relevant operational and environmental factors.\n",
    "\n",
    "The Data Engineering & Checkpointing stage prepares the dataset for modeling. The pipeline begins by performing a temporal split into training, validation, and test sets following a 70/10/20 ratio by time. To prevent data leakage and ensure causal validity, a two-hour exclusion gap is introduced between the training and validation windows. This ensures that no information about future flights leaks into the training process. Each major transformation step (splitting, cleaning, feature engineering) is checkpointed, enabling efficient re-runs and consistent intermediate outputs. Engineered features, such as lagged delay metrics, temporal indicators, and weather-derived variables, are stored in a Feature Store, allowing for reusability across models and experiments.\n",
    "\n",
    "The Modeling & Time-Series Cross-Validation stage formalizes model training and evaluation through a rolling window cross-validation scheme. The dataset is divided into five temporal folds, separated by a 2-hour gap. This design closely mirrors real-world airline operations, where predictions must be made two hours prior to departure, and future data cannot be accessed at prediction time. Each fold trains a complete preprocessing and modeling pipeline, applies hyperparameter tuning, and evaluates performance metrics. The final model is retrained on the full training period and stored alongside the fitted preprocessing pipeline to ensure complete reproducibility.\n",
    "\n",
    "The Evaluation, Deployment, and Monitoring stage validates the final model on a held-out test set that represents future, unseen data. Experiment tracking through MLflow records metrics, hyperparameters, and artifacts, enabling transparent model comparison. The best-performing models are registered in the Model Registry and deployed to production where predictions are generated at least two hours before scheduled departure. \n",
    "\n",
    "Continuous monitoring is implemented to detect performance drift and trigger scheduled retraining, ensuring long-term model reliability and alignment with operational conditions.\n",
    "Overall, this pipeline design emphasizes reproducibility, leakage prevention, and temporal validity. The inclusion of structured checkpoints and feature versioning ensures that each experiment remains traceable and recoverable, while the rolling validation design provides an empirically sound foundation for model selection and performance reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f8fa8fd-1d37-4e95-aeb4-e7833683ccd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<!-- ![261_ML_Pipeline5.png](/Workspace/Users/seowyang@berkeley.edu/261_ML_Pipeline5.png) -->\n",
    "<!-- \n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/261_ML_Pipeline5.png\"> -->\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/261_ML_Pipeline5.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a36d8b09-d76f-4169-84ef-001418398b64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Deep Dive: Checkpoint Strategy\n",
    "\n",
    "<!-- ![checkpointing.png](/Workspace/Users/seowyang@berkeley.edu/checkpointing.png) -->\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/checkpointing.png\">\n",
    "\n",
    "We're converting all CSVs into Parquet format for our data ingestion pipeline, which offers significant advantage in terms of storage efficiency and faster read/writes.\n",
    "\n",
    "For checkpoint strategy: we first split the combined dataset into train, test, and validation sets to prevent any data leakage, establishing this as our initial checkpoint. This step was critical because as it ensures that all subsequent transformations are fitted exclusively on training data, preventing any leakage. We then preprocessed the training data by applying techniques such as imputation for missing values, and standardization for numerical features, checkpointing the cleaned dataset at the stage. Then, we developed our feature engineering pipeline, carefully fitting on training data, and transforing the three splits accordingly, with another checkpoint capturing these fully transformed datasets. Throughout the preprocessing and feature engineering stages, we built and saved the complete training pipeline, encapsulating all transformation steps for reproducibility.\n",
    "\n",
    "We created and checkpointed cross-validation folds, and trained/validated our models, saving both the training and performance resutls. The best performing model was selected, trained with the best performing hyperparamters, and the pipeline was tested on the test data (unseen) to evaluate real-world performance.\n",
    "\n",
    "This systematic checkpointing approach creates clear recovery points throughout our workflow, allowing us to iterate efficiently on different stages without reprocessing from scratch, preventing data leakage, and ensuring reliable model evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67edbe97-bf88-4418-929e-789a59981732",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Feature Selection and Feature Engineering\n",
    "\n",
    "After preparing the train, test and validation splits, we moved to feature engineering. The custom join handled many of the features with more than 20% nulls in the combined join, and ignoring cancelled flights handled most of the remaining nulls. Our target variable is DEPARTURE DELAY NEW where all the values are greater than or equal to 0. Since we will need to make this prediction 2 hours before the scheduled departure, we implemented strict feature filtering to prevent data leakage. This involved excluding any columns containing data that would be unavailable at the time of prediction. So from our final joined dataset with 121 possible features, these filters helped to narrow down our actually usable fields\n",
    "\n",
    "Because most delays are due to weather, maintenance, or late-arriving aircraft, we relied on the provided weather data and constructed lagged or derived features to model operational constraints. These engineered features specifically capture the potential cascade effect of maintenance problems or disruptions caused by late inbound flights.\n",
    "\n",
    "Our Exploratory Data Analysis (EDA) of the raw flight data, combined with the integrated weather dataset, revealed significant non-linear dependencies and temporal patterns leading us to develop rolling aggregate features and interaction terms that capture systemic risk and momentum, which are necessary to overcome the limitations of the raw variables.\n",
    "\n",
    "For the baseline model, we used a total of 33 input features spanning flight metadata, weather conditions, immediate system status, and aggregate engineered history.\n",
    "\n",
    "The number of input features in each family are:\n",
    "- Flight metadata: 12\n",
    "- Immediate system status: 3\n",
    "- Aggregate and Engineered history: 7\n",
    "- Weather conditions: 11\n",
    "\n",
    "The Flight and Weather Metadata family includes data known well in advance of the flight or sourced externally, such as fixed route information, carrier identifiers, date/time components, and all Weather Conditions (e.g., temperature, wind speed) integrated from the custom joined dataset. The Immediate System Status family is highly crucial as it captures the real-time operational state of the aircraft and the immediate environment, identifying features that directly contribute to cascading delays. Examples include tracking the aircraft's current workload by calculating the proportion of its daily scheduled flights already completed, and calculating the Turnaround Time Gap, the small difference between a plane's scheduled landing time from its previous flight and its next scheduled take-off time.\n",
    "\n",
    "Finally, the Rolling Aggregates and Systemic History family utilizes a 7-day rolling window to compute historical summaries for systemic risk, such as the average arrival delay and taxi-out time for each airport, and the total number of delays associated with a specific route or departure location, effectively capturing underlying congestion and systemic performance trends. This comprehensive set of engineered features, spanning static context to real-time momentum, ensures the model has the necessary inputs to produce highly predictive delay forecasts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d09e911e-5a28-4cb4-8224-f7a3464395f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Feature Selection: Baseline Model Experimentation\n",
    "In order to select the a basline model to tune, we tested a few algorithms and documented their results in MLFlow. \n",
    "\n",
    "The cluster used was:\n",
    "- Runtime: `16.4ML, Spark 3.5.2, Scala 2.12`\n",
    "- Driver: `m5d.xlarge, 16GB, 4 cores`\n",
    "- Workers (2-8): `m5d.xlarge, 32-128GB, 8-32 cores`\n",
    "\n",
    "The runtimes for each model with all 33 input features:\n",
    "- Random Forest: 15.9 minutes\n",
    "- XGBoost: 9.7 minutes\n",
    "\n",
    "In total, we ran 6 different experiments on the 1 year dataset with different regression algorithms and number of input features to establish our baseline model. The first set of features was only the flight metadata, the second set was the flight metadata and weather conditions, and the third was the flight metadata, weather conditions and engineered features.\n",
    "\n",
    "Experimental Results for Random Forest (1 year)\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/ph2_rf_experiments.png\">\n",
    "\n",
    "Experimental Results for XGBoost (1 year)\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/phase2_xgb_experiments.png\">\n",
    "\n",
    "\n",
    "Metrics for performance tracking used were:\n",
    "\n",
    "Mean absolute error:\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "Root Mean Squared Error:\n",
    "$$\\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2}$$\n",
    "\n",
    "The iterative evaluation of our modeling pipeline demonstrates that the incorporation of hourly weather conditions and domain-specific engineered features is critical for achieving significant improvements in predictive metrics. This success validates our core strategy, the final model must synthesize information from three distinct domains, moving beyond simple static scheduling to accurately capture the dynamic operational reality of the air travel system. \n",
    "\n",
    "The inclusion of weather conditions and the immediate system status features, such as the turnaround time gap and the aircraft's flight sequence progress, allows the model to shift from baseline prediction to a condition-based risk assessment, effectively capture the potential for cascading delays.The rolling aggregates act as crucial proxies for system congestion and momentum, providing the model with a robust, low-noise signal of underlying systemic risks. \n",
    "\n",
    "As these features collectively prove essential in reducing unexplained variance and maximizing predictive fidelity, we will proceed with the full 33-feature set for all subsequent model development and hyperparameter tuning efforts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7efd80fd-ab1a-452b-939b-d602f1513296",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Deep Dive: Cross Validation Strategy\n",
    "\n",
    "<!-- ![cross_validaiton.png](/Workspace/Users/seowyang@berkeley.edu/cross_validation.jpeg) -->\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/cross_validation.jpeg\">\n",
    "\n",
    "To evaluate model performance while preventing data leakage, we used a time-series cross-validation approach with a mandatory two-hour gap between training and validation periods.\n",
    "\n",
    "Since predictions must be made 2 hours prior to scheduled departure, we implemented a sliding window schema where each fold consists of three components: a training period, a 2-hour gap period, and a validation period. The 2-hour gap ensures that no information from after the prediction time can inadvertently influence model training. This gap is critical for flight delay prediction because delays cascade through airline networks. For example, a flight delayed at 3:00 PM may affect subsequent departures. Without a temporal gap, the model could learn from information that would not be available at prediction time. When predicting a 4:00 PM departure at 2:00 PM, we can only use delay information from flights that departed before 2:00 PM—not the 3:00 PM flight's outcome. The rolling window approach maintains consistent training set sizes across folds, ensuring stable model performance and comparable computational requirements.\n",
    "\n",
    "Our validation strategy uses 5 folds with rolling windows across our datasets spanning 3 months and 1 year, respectively. The table below summarizes the cross-validation parameters for both datasets:\n",
    "| **Parameter** | **3-Month Data** | **1-Year Data** |\n",
    "|--------------|------------------|-----------------|\n",
    "| Number of folds | 5 | 5 |\n",
    "| Training window | 30 days | 4 months |\n",
    "| Gap period | 2 hours | 2 hours |\n",
    "| Validation window | 7 days | 1 month |\n",
    "| Step size (fold advancement) | ~8 days | ~36 days |\n",
    "\n",
    "**Note:** Each fold consists of a training period, followed by a 2-hour gap to prevent data leakage, and then a validation period. Consecutive folds start at intervals defined by the step size, creating substantial overlap that ensures comprehensive temporal coverage while maintaining prediction integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf8ef224-db0d-4277-af33-462802f129a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Machine Algorithms and Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7065984d-a8f4-4d8b-bc35-8204d303e79a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Machine Learning Algorithms & Design\n",
    "\n",
    "Our EDA revealed the data is quite noisy and has a lot of missing values. While we have a strong preprocessing and filtering strategy to mitigate this, we still anticipate some amount of data imperfections to reach our model pipeline. To address this, we will use a cascade model where the first model is a regression model predicting the travel delay in minutes, and the second model is a classification model classifying if the delay is slightly delayed, moderately delayed, significantly delayed or severely delayed. This report focuses primarily on the regression model, but some plan details are included below:\n",
    "\n",
    "**Regression Model (Tier 1)**\n",
    "- Implementation: `XGBoost`\n",
    "- Loss Function: Mean Absolute Error (MAE)\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "**Classification Model (Tier 2)**\n",
    "- Implementation: `Random Forest`\n",
    "-  Loss Function: Multiclass Cross Entropy\n",
    "\n",
    "$$\n",
    "\\text{Cross-Entropy Loss } (L) = -\\sum_{i=1}^{N} \\sum_{c=1}^{C} y_{i,c} \\log(p_{i,c})\n",
    "$$\n",
    "\n",
    "\n",
    "The regression model is designed to leverage the inherent noise-tolerance of ensemble tree models and architected to perform non-linear feature engineering. With XGBoost, the model learns the optimal direction for a split when an observation’s feature value is missing, strengthening the model's resilience against features with high dimensionality of null entries and preserving predictive integrity. XGBoost’s built in regularization feature and second-order Taylor approximation optimization makes it a better option over Random Forest or linear regression. With this regression model we are creating a highly informed prediction for the target. The loss function will be the mean absolute error since the data is noisy and contains outliers. This prediction is more powerful and reliable than any single, raw input feature, making the input to the classifier cleaner.\n",
    "\n",
    "This clean, predictive output goes straight into the classification model as a denoised feature. The Random Forest classifier now benefits from this highly reliable signal, its job is much simpler, and we get dramatically improved accuracy and stability. Random Forest offers intrinsic robustness to residual variance from the regression model, and its bagging ensemble mechanism mitigates high variance that resists overfitting. The parallelizable training methodology also accelerates the fitting process and inference latency, ideal for our large datasets. For our baseline, we will use multiclass cross-entropy log loss, but suspect we may need to use a more advanced loss function like focal loss to address the highly imbalanced data. \n",
    "\n",
    "$$\n",
    "\\text{Focal Loss} (p_t) = -\\alpha_t (1 - p_t)^\\gamma \\log(p_t)\n",
    "$$\n",
    "\n",
    "This tiered structure gives us valuable diagnostic capability, so if the final prediction is wrong, we can look at the regression model's output to immediately pinpoint whether the problem was a poor magnitude estimate or a failed classification boundary.\n",
    "\n",
    "A final classification output was selected for its interpretability and risk assessment for front-line decision-makers. While the regression model output provides a high-fidelity magnitude estimate, the classification model explicitly maps this magnitude to a probability distribution over predefined operational states. The discrete output immediately determines resource allocation, enabling controllers to instantly decide if a flight needs a gate change, if a crew will time out, or if air traffic sequencing must be altered, thus optimizing real-time decision-making where precise actions, not continuous predictions, are required.\n",
    "\n",
    "In order to compare the our baseline regression model to the final classification model, we will use Mean Absolute Error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32438866-3969-45e4-baa9-f2faa1b6301c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Metrics\n",
    "\n",
    "In order to deliver a model that best suits the needs of air traffic controllers, we need to optimize for metrics that account for both the costs and benefits of our predictions, as well as the class balance of our dataset.\n",
    "\n",
    "For example, consider the following outcomes of our final model:\n",
    "\n",
    "- True Positive: We correctly predict that a flight will be delayed. This could allow air traffic controllers to re-allocate gates and runways, potentially saving several minutes for dozens of flights - a huge net gain especially during congestion.\n",
    "- True Negative: We correctly predict that a flight will be on time. This will help air traffic controllers to focus on other flights more likely to need their attention.\n",
    "- False Positive: We incorrectly predict that a flight will be delayed. This could cause several planes to be re-routed unnecessarily and cause the flight in question to circle the skies waiting to land and waiting to park at their previously allocated gate. This mistake could snowball to downstream flights and occupy stand-by space that other genuinely delayed flights may need.\n",
    "- False Negative: We incorreclty predict that a flight will be on time. There will be idle space on the runways, and air traffic controllers will miss the opportunity to make up for other true delays. These delays can easily pile up throughout the day, and can leave both air traffic controllers and passengers blindsided.\n",
    "\n",
    "Additionally, it is important that our metrics account for the fact only around 18.29% of flights are delayed by 15 minutes or more, leading to significant class imbalance. We don't want our validation metrics to lead us to chose a model that fails to learn the important minority class.\n",
    "\n",
    "<!-- ![response_dist.png](/Workspace/Users/seowyang@berkeley.edu/response_dist.png) -->\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/response_dist.png\">\n",
    "</div>\n",
    "\n",
    "Between class imbalance and prediction consequences, the former will inform our choice of validation metric for model selection, while the latter will help us choose a classification threshold that leverages our model's predictive power while also optimizing for airport safety KPIs. To this end, a few of validation metrics are disqualified:\n",
    "\n",
    "- Accuracy: This metric is notoriously sensitive to class imbalance, and could lead us to optimize for a model that fails to learn the minority class at all by simply always predicting the majority class.\n",
    "- ROC-AUC: Similarly, this metric does not handle class imbalance well. Integrating under a curve plotting true-positive rate (TP / (TP + FN)) against false-positive rate (FP / (FP + TN)). If the negative class is large and a model largely favors classifying records as negative, the FPR will have a much larger denominator and comparable numerator, causing X to tend smaller than Y - inflating the ROC-AUC integral of this faulty model and hurting downstream KPIs.\n",
    "\n",
    "While precision and recall are both valid options for a key metric, focusing on one and not the other would ignore important consequences of our model. Precision ignores false negatives, and recall ignores false positives. If there are known costs associated with these errors, both are necessary in choosing our model, and both our validation metric and thresholding metric should account for this.\n",
    "\n",
    "Thus, for our validation metric we will use PRC-AUC, helping us to select a model that will give us the best balance between precision and recall regardless of threshold. This will set us up for success to use F_1 as a metric when deciding our threshold. If information about the cost associated with any of the four classification outcomes, we could empirically determine the costs of false positives and false negatives to choose a Beta to optimize F_Beta and choose a threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8045b093-299d-4956-b352-c96f5fe5b065",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Hyperparameter Tuning\n",
    "\n",
    "We performed hyperparameter tuning for our best performing model, the XGBoost Regressor, using cross-validation with the time-series splitting scheme described above. We selected these hyperparameters to balance model complexity and generalization: `max_depth` [4, 6] controls individual tree complexity, `n_estimators` [20, 50, 100] determines ensemble size, and `learning_rate` [0.05, 0.1] provides step size shrinkage to prevent overfitting. These ranges represent commonly effective values for XGBoost while remaining computationally feasible for our 5-fold cross-validation approach.\n",
    "We validated each combination using our 5-fold cross-validation approach with 2-hour gaps, resulting in 12 total parameter combinations. The results are shown in the table below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "147b2d7e-1a09-4747-bb22-deafb8be40aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Based on our findings, we selected the XGBoost Regressor configuration from row 1 (max_depth=6, n_estimators=100, learning_rate=0.05), achieving validation MAE of 17.565 with standard deviation of 0.823."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32de47e1-9c64-4050-b46e-5f6c233d8ea5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "![](CV_RESULTS_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b464434b-c1f1-4770-b279-09e2ee1ea679",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "#### Overview of Experimental Setup\n",
    "We partitioned the full 1-year dataset into a training period (first three quarters) and a blind test period (final quarter). Phase 2 focused on comparing regression models for predicting continuous flight delays, while Phase 3 will expand on the analysis to classification performance using thresholding at 15 minutes and evaluate the role of the two-stage pipeline.\n",
    "\n",
    "The motivation of this 2-stage model is to both preserve the rich continuous signal of our response variable while also performing a downstream binary classification of \"On-Time\" or \"Delayed\". Towards implementing a quantile regression to identify easy/hard flights to classify during Phase 3, we based model selection in Phase 2 on validation MAE.\n",
    "\n",
    "#### Model Loss Comparison\n",
    "\n",
    "Several regression model families were evaluated during Phase 2, including Linear Regression, Random Forests, and XGBoost. The below table summarizes the best 5-fold cross-validated MAE results (in minutes delay) from each of our models on both the 3-month and 1-year datasets.\n",
    "\n",
    "| Dataset | 3 months | 1 year |\n",
    "|---------|----------|--------|\n",
    "| **Model** | **Train / Val MAE** | **Train / Val MAE** |\n",
    "| Linear Regression | 16.006 / 13.475 | 18.852 / 15.839 |\n",
    "| Random Forest Regressor | 13.860 / 15.79 | 15.382 / 17.565 |\n",
    "| **XGBoost Regressor** | 14.281 / **12.974** | 16.354 / **13.284** |\n",
    "\n",
    "Across models, XGBoost provided the best balance of predictive accuracy and training stability, achieving the lowest validation MAE on both datasets. This indicates meaningful non-linear interactions among our flight delay features.\n",
    "\n",
    "#### Cross-Validation\n",
    "\n",
    "The below table details our hyperparameter grid search for the XGBoost model.\n",
    "\n",
    "| Hyperparameter   | Values                 |\n",
    "|------------------|------------------------|\n",
    "| `max_depth`      | 4, 6                   |\n",
    "| `n_estimators`   | 20, 50, 100            |\n",
    "| `learning_rate`  | 0.05, 0.1              |\n",
    "\n",
    "\n",
    "During K-fold cross-validation on the training set, the selected XGBoost regressor with:\n",
    "\n",
    "- `max_depth = 6`  \n",
    "- `n_estimators = 100`  \n",
    "- `learning_rate = 0.05`  \n",
    "\n",
    "achieved:\n",
    "\n",
    "- **avg validation MAE = 13.284**  \n",
    "- **avg training MAE = 16.354**  \n",
    "- **std of validation MAE = 0.823**\n",
    "\n",
    "indicating moderate fold-to-fold consistency. These results suggest that the model captured sufficient complexity without severe overfitting, making it the clear choice as the Stage-1 predictor in our two-stage system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5011dca-21d4-4398-8a02-9269d20778de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Blind Test Performance (Final Quarter of the Dataset)\n",
    "\n",
    "On the held-out blind test set representing the final quarter of the year, the selected model achieved: **Test MAE = 14.32**\n",
    "\n",
    "This constitutes an improvement relative to both the training and validation MAE, indicating strong generalization and suggesting that the distributions in the test quarter are not substantially more volatile than those in the training period. The low MAE also demonstrates that the model captures the central tendency of flight delays, which will be essential for the quantile-based decision-making in Phase 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f83010a2-f43b-4216-9c53-763448ff4206",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<!-- ![](TRAIN_TEST_VAL_RESULTS.png) -->\n",
    "<img src=\"TRAIN_TEST_VAL_RESULTS.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30244459-d85a-447c-815a-e37f2c341041",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Regressor-as-Classifier Baseline\n",
    "To establish a baseline for Phase 3's two-stage pipeline, we evaluated the classification performance of the regression model by thresholding predicted delay at 15 minutes. This aligns with our downstream task of classifying all flights as either \"On-Time\" or \"Delayed.\"\n",
    "\n",
    "Because failing to identify a meaningful delay (false negative) is more costly than incorrectly predicting one (false positive), we use **F₂ score** as our north-star metric.\n",
    "\n",
    "On the blind test set:\n",
    "\n",
    "- **Precision = 0.4533**  \n",
    "- **Recall = 0.5645**  \n",
    "- **F₂ = 0.5374**\n",
    "\n",
    "The model exhibits moderate recall, consistent with expectations for MAE-optimized quantile regression, which tends to reduce underestimation errors. Precision is lower, highlighting the trade-off inherent to regression-based classifiers. Phase 3 will introduce our second-stage classifier to address this limitation.\n",
    "\n",
    "#### Experiments and Pipelines\n",
    "\n",
    "The experiments conducted across Phases 2 and 3 provide several insights into the performance and viability of the pipelines considered:\n",
    "\n",
    "**Regression-only pipeline**\n",
    "- Performs well in predicting continuous delays (low MAE).  \n",
    "- Underperforms as a classifier, with modest precision and only moderate recall.  \n",
    "- Not ideal when operational priorities emphasize catching all true delays.\n",
    "\n",
    "**Two-stage pipeline**\n",
    "- Quantile regression maintains the full richness of the continuous delay signal.  \n",
    "- The second stage focuses classification efforts on the “uncertain band” where delays around the 15-minute threshold are most ambiguous.  \n",
    "- Expected to improve precision and reduce unnecessary interventions while maintaining high recall.\n",
    "\n",
    "Overall, experimental results strongly support the use of the two-stage pipeline, as the regression-only classifier baseline fails to meet precision–recall tradeoffs appropriate for operational settings.\n",
    "\n",
    "\n",
    "#### Broader Perspective and Implications\n",
    "\n",
    "From a broader modeling perspective, these results highlight several important themes:\n",
    "\n",
    "- **Temporal generalization matters.** Training on three quarters and testing on the final quarter mimics real-world deployment and demonstrates that the model can handle natural seasonal shifts in flight traffic patterns.\n",
    "\n",
    "- **Operational costs shape metric use.** Since false negatives (missed delays) appear more harmful than false positives, metrics such as F₂ are more appropriate than accuracy or F₁.\n",
    "\n",
    "- **Model architecture reflects the problem structure.** Preserving continuous delay prediction enables more nuanced downstream decision-making than pure classification. The two-stage structure leverages this continuity while still addressing the discrete operational threshold.\n",
    "\n",
    "- **XGBoost is more suited to flight data than linear models.** XGBoost's performance suggests that flight-delay prediction is inherently non-linear and influenced by interactions among weather, congestion, aircraft characteristics, and scheduling features. This motivates our addition of graph features and MLP models in Phase 3.\n",
    "\n",
    "\n",
    "The combined experimental and cross-validated results converge on a clear high-performance configuration. Both the systematic hyperparameter sweep and the cross-validation study identify max_depth = 6, n_estimators = 100, and learning_rate = 0.05 as the most reliable and generalizable parameter set. This model's train and validation MAE align closely with the earlier experiments' (with different depths and estimators) indication that deeper trees and larger ensembles effectively capture the nonlinear structure underlying delay behavior.\n",
    "\n",
    "When evaluated on the final test set, data never seen during tuning, the model not only maintained its generalization but exceeded expectations, achieving a Test MAE of 14.32, outperforming both cross-validation and blind-validation benchmarks. This reinforces that the selected capacity level leverages meaningful signal rather than overfitting to noise.\n",
    "From an operational perspective, the model set the foundation for downstream decision-support scenarios that require delay/no-delay classification. While not optimized explicitly for classification, it still achieved a Precision of 0.4533, Recall of 0.5645, and an F2 score of 0.5374, a favorable balance for applications where identifying likely delays (recall-heavy behavior) is more critical than minimizing false positives.\n",
    "\n",
    "Overall, the evidence strongly supports deploying a high-capacity gradient boosting model (depth 6, 100 estimators) as the primary pipeline for predicting flight delays. It offers a compelling combination of accuracy, robustness, and real-world utility, with demonstrated consistency across training, validation, and fully held-out test data. This configuration meaningfully reduces predictive uncertainty and provides a dependable foundation for both operational forecasting and decision-support systems in airline and airport environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6830f070-31d5-4d75-b838-bbddd1d1e4b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1fd178c-d0cb-4db0-8691-f3cf2ede0919",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This project set out to build a dependable machine-learning system capable of forecasting flight delays, a task central to air traffic controllers who must anticipate congestion and maintain safe, efficient traffic flow. We hypothesized that ML pipelines enriched with custom, domain-aware features, especially a kriging-interpolated weather join, would provide accurate and operationally meaningful delay predictions.\n",
    "\n",
    "The experiments confirm this hypothesis. By evaluating a structured set of model configurations, we found that pipelines combining deeper boosted trees with our enhanced feature set consistently offered the strongest and most stable performance across both training data and blind testing. The custom feature engineering played a particularly important role: the kriging-based weather surfaces and tailored joins added spatial and temporal fidelity that traditional features alone could not capture. These richer representations allowed the models to better learn the complex interplay between weather, traffic conditions, and delay outcomes.\n",
    "\n",
    "The results underscore a key contribution of this work: model capacity matters, but domain-specific feature engineering matters more. Our latest model succeeded because it was designed to ingest information that reflects how delays truly develop in real airspace operations. This makes the resulting predictions more aligned with the realities air traffic controllers face each day.\n",
    "\n",
    "With a strong XGBoost Regression model established, the next phase of our work will introduce a classification layer that directly leverages the denoised, high-signal output generated by the XGBoost regressor. The regression stage was deliberately designed to capitalize on the noise tolerance, non-linear feature construction, and split-optimization strengths of boosted tree ensembles. By learning optimal split directions even when feature values are missing, managing high-null-dimensionality inputs, and applying built-in regularization to control complexity, the XGBoost layer produces a highly reliable delay prediction. This refined signal provides a clean, model-informed foundation on which the downstream classifier can operate with much greater accuracy and stability.\n",
    "\n",
    "Overall, this project lays the groundwork for a predictive framework that can evolve with additional data sources and relationships within data, more advanced imbalance-aware loss functions, and future operational constraints. Most importantly, it demonstrates that thoughtful ML design, grounded in domain expertise, can deliver tools that meaningfully support air traffic controllers in managing an increasingly complex airspace.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c37024f2-3500-4bf4-bee7-252869aae530",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Appendix\n",
    "\n",
    "* Link to Data Dictionary of all original features and EDA\n",
    "* Team Planning & Gantt Chart\n",
    "* Link to GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7000c8e9-47dc-407d-a53a-9f6211799596",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Link to Data Dictionary of all original features and EDA:\n",
    "https://github.com/stephanie-cal/mids261-final_project/notebooks_RS/w261_final_project_EDA_phase_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ebe017c-6249-4cea-8ac7-313a9769a73a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Team Planning: Gantt Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e70f5d4f-7566-4968-b888-af7e1cc184f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To streamline progress monitoring and accountability, we have developed a dynamic project tracker that provides real-time updates on task ownership and internal deadlines. The project is structured into phased milestones, each aligned with client deliverables, submission requirements, and upcoming requests.\n",
    "Leadership rotates weekly, designating a different team member as lead to encourage shared ownership and diverse decision-making perspectives. Regular check-ins are scheduled to maintain alignment and foster collaboration across workstreams.\n",
    "\n",
    "Phases are interdependent by design. For example, the initial exploratory data analysis (EDA) conducted this week establishes the foundation for deeper analytical work and advanced EDA during subsequent feature engineering stages. This progressive approach ensures that insights evolve alongside the modeling pipeline.\n",
    "\n",
    "Finally, we have collectively discussed team priorities, individual development goals, and preferred working styles to optimize task allocation, leverage existing expertise, and provide opportunities for growth in new technical areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a9b9041-978e-4dbf-912f-c853a6a68278",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<!-- ![261_Gantt_Chart_Project_Plan.png](/Workspace/Users/seowyang@berkeley.edu/261_Gantt_Chart_Project_Plan.png) -->\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/stephanie-cal/mids261-final_project/main/261_Gantt_Chart_Project_Plan.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "782fb393-4eb6-4ad8-9589-e1adbdf39aa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Link to the code repository: \n",
    "https://github.com/stephanie-cal/mids261-final_project\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "[Team_2-2] Phase 2 Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
