{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46f0190e-ca20-42f1-a87e-a3db6d8ecc04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "466c9b79-14bf-4db7-906c-23b1354bd52f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from xgboost.spark import SparkXGBRegressor\n",
    "\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "print(mlflow.__version__)\n",
    "\n",
    "import os\n",
    "\n",
    "spark.conf.set(\"spark.databricks.mlflow.trackMLlib.enabled\", \"true\")\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "# Define experiment name with proper Databricks path\n",
    "EXPERIMENT_NAME = \"/Shared/team_2_2/mlflow-baseline\"\n",
    "# Create the experiment if it doesn't exist\n",
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if experiment is None:\n",
    "        experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "        print(f\"Created new experiment with ID: {experiment_id}\")\n",
    "    else:\n",
    "        print(f\"Using existing experiment: {experiment.name}\")\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "except Exception as e:\n",
    "    print(f\"Error with experiment setup: {e}\")\n",
    "    # Fallback to default experiment in workspace\n",
    "    mlflow.set_experiment(f\"/Users/{dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()}/default\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9290ed1e-5341-4a89-a730-57a3fa316399",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.ml import Estimator, Model\n",
    "# from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "# from pyspark.sql.functions import col, lit, when\n",
    "# from pyspark.sql import DataFrame\n",
    "# from pyspark.sql.functions import count as f_count\n",
    "\n",
    "# class IntervalClassifier(Estimator, DefaultParamsReadable, DefaultParamsWritable):\n",
    "\n",
    "#     def __init__(self,\n",
    "#                  lowerEstimator,\n",
    "#                  upperEstimator,\n",
    "#                  baseClassifier,\n",
    "#                  labelCol=\"delay_minutes\",\n",
    "#                  featuresCol=\"features\",\n",
    "#                  predictionCol=\"final_prediction\",\n",
    "#                  threshold=15.0,\n",
    "#                  quantile_gap=0.1,\n",
    "#                  qLowCol=\"low_pred\",\n",
    "#                  qHighCol=\"high_pred\",\n",
    "#                  clfPredictionCol=\"clf_prediction\",\n",
    "#                  undersample_majority=True,\n",
    "#                  undersample_seed=42):\n",
    "#         super().__init__()\n",
    "#         self.lowerEstimator = lowerEstimator\n",
    "#         self.upperEstimator = upperEstimator\n",
    "#         self.baseClassifier = baseClassifier\n",
    "#         self.labelCol = labelCol\n",
    "#         self.featuresCol = featuresCol\n",
    "#         self.predictionCol = predictionCol\n",
    "#         self.threshold = float(threshold)\n",
    "#         self.quantile_gap = float(quantile_gap)\n",
    "#         self.qLowCol = qLowCol\n",
    "#         self.qHighCol = qHighCol\n",
    "#         self.clfPredictionCol = clfPredictionCol\n",
    "#         self.undersample_majority = undersample_majority\n",
    "#         self.undersample_seed = undersample_seed\n",
    "\n",
    "#     def _fit(self, dataset: DataFrame) -> Model:\n",
    "#         # 1) Fit quantile regressors on ALL data\n",
    "#         print(\"Training Lower Estimator...\")\n",
    "#         lowerModel = self.lowerEstimator.fit(dataset)\n",
    "#         print(\"Training Upper Estimator...\")\n",
    "#         upperModel = self.upperEstimator.fit(dataset)\n",
    "\n",
    "#         # ---------------------------------------------------------------\n",
    "#         \"\"\"\n",
    "#         booster = lowerModel.get_booster()\n",
    "\n",
    "#         # ---- Gain importance from Booster ----\n",
    "#         # XGBoost uses f0, f1, ... in order of the feature vector\n",
    "#         gain_dict = booster.get_score(importance_type=\"gain\")  # e.g. {\"f0\": 0.3, \"f2\": 0.1, ...}\n",
    "\n",
    "#         # Map f0, f1, ... back to your feature names\n",
    "#         rows = []\n",
    "#         for i, feat_name in enumerate(model_cols_final):\n",
    "#             key = f\"f{i}\"\n",
    "#             gain = gain_dict.get(key, 0.0)\n",
    "#             rows.append((feat_name, gain))\n",
    "\n",
    "#         gain_df = pd.DataFrame(rows, columns=[\"feature\", \"gain\"]).sort_values(\"gain\", ascending=False)\n",
    "#         print(\"Gain:\")\n",
    "#         print(gain_df)\n",
    "\n",
    "#         sample_vec = assembler.transform(train_df).select(\"features\").limit(500)  # or whatever size\n",
    "\n",
    "#         X_local = np.stack(\n",
    "#             sample_vec.rdd.map(lambda row: row[\"features\"].toArray()).collect()\n",
    "#         )\n",
    "\n",
    "#         # ---- SHAP on the Booster ----\n",
    "#         explainer = shap.TreeExplainer(booster)\n",
    "#         shap_values = explainer.shap_values(X_local)\n",
    "\n",
    "#         # Mean abs SHAP importance per feature\n",
    "#         shap_importance = (\n",
    "#             pd.DataFrame({\n",
    "#                 \"feature\": model_cols_final,\n",
    "#                 \"shap_importance\": np.abs(shap_values).mean(axis=0)\n",
    "#             })\n",
    "#             .sort_values(\"shap_importance\", ascending=False)\n",
    "#         )\n",
    "\n",
    "#         print(shap_importance.head(20))\n",
    "\n",
    "\n",
    "#         # ---------------------------------------------------------------\n",
    "#         print(\"END\")\n",
    "#         \"\"\"\n",
    "        \n",
    "#         print(\"Configuring Classifier...\")\n",
    "#         # 2) Add qLow and qHigh predictions\n",
    "#         df_q = lowerModel.transform(dataset) \\\n",
    "#                          .withColumnRenamed(\"prediction\", self.qLowCol)\n",
    "\n",
    "#         df_q = upperModel.transform(df_q) \\\n",
    "#                          .withColumnRenamed(\"prediction\", self.qHighCol)\n",
    "\n",
    "#         # 3) Keep only examples where 15 is between qLow and qHigh\n",
    "#         print(\"Filtering ambiguous cases...\")\n",
    "#         thr = lit(self.threshold)\n",
    "#         df_ambig = df_q.filter(\n",
    "#             (col(self.qLowCol) <= thr) & (thr <= col(self.qHighCol))\n",
    "#         )\n",
    "\n",
    "#         # 4) Build binary label: 1 if delay ≥ threshold, else 0\n",
    "#         df_ambig = df_ambig.withColumn(\n",
    "#             \"bin_label\",\n",
    "#             (col(self.labelCol) >= thr).cast(\"double\")\n",
    "#         )\n",
    "\n",
    "#         # save df_ambig to disk\n",
    "#         run_name = 'XGB-3m_2_stage_opt_low_0.380_high_1.000'\n",
    "        \n",
    "#         ambig_dest = f\"dbfs:/student-groups/Group_2_2/2_stage_dev_files/df_ambig_{run_name}.parquet\"\n",
    "#         print(\"Saving ambig dataset to parquet at\", ambig_dest)\n",
    "#         df_ambig.write.mode(\"overwrite\").parquet(ambig_dest)\n",
    "\n",
    "#         print(\"Undersampling...\")\n",
    "#         # --- undersample majority class among ambiguous cases ---\n",
    "#         if self.undersample_majority:\n",
    "#             # class counts on driver (only 2 classes)\n",
    "#             class_counts = (\n",
    "#                 df_ambig.groupBy(\"bin_label\")\n",
    "#                         .agg(f_count(\"*\").alias(\"cnt\"))\n",
    "#                         .collect()\n",
    "#             )\n",
    "\n",
    "#             # If we have both classes, find minority/majority and undersample\n",
    "#             if len(class_counts) != 2:\n",
    "#                 raise ValueError(\"Ambiguous cases must contain both classes.\")\n",
    "\n",
    "#             (label0, cnt0), (label1, cnt1) = [\n",
    "#                 (row[\"bin_label\"], row[\"cnt\"]) for row in class_counts\n",
    "#             ]\n",
    "\n",
    "#             if cnt0 <= cnt1:\n",
    "#                 minority_label, minority_cnt = label0, cnt0\n",
    "#                 majority_label, majority_cnt = label1, cnt1\n",
    "#             else:\n",
    "#                 minority_label, minority_cnt = label1, cnt1\n",
    "#                 majority_label, majority_cnt = label0, cnt0\n",
    "\n",
    "#             print(f\"Undersampling majority class {majority_label} from {majority_cnt} to {minority_cnt}.\")\n",
    "\n",
    "#             if majority_cnt > 0 and minority_cnt > 0:\n",
    "#                 frac_majority = float(minority_cnt) / float(majority_cnt)\n",
    "\n",
    "#                 # sampleBy keeps all minority, downsamples majority\n",
    "#                 fractions = {\n",
    "#                     float(minority_label): 1.0,\n",
    "#                     float(majority_label): frac_majority\n",
    "#                 }\n",
    "\n",
    "#                 df_ambig = df_ambig.sampleBy(\n",
    "#                     \"bin_label\",\n",
    "#                     fractions=fractions,\n",
    "#                     seed=self.undersample_seed\n",
    "#                 )\n",
    "#         # --- END undersampling block ---\n",
    "\n",
    "#         print(\"Training Base Classifier...\")\n",
    "#         # 5) Fit classifier on (possibly undersampled) ambiguous region\n",
    "#         # NOTE: If you change the baseClassifier, make sure that these methods still work. If not, look up\n",
    "#         # what the corresponding methods are to achieve the same functionality as the .setParams and .fit methods\n",
    "#         clf = self.baseClassifier\n",
    "        \n",
    "#         clf.setParams(\n",
    "#             label_col=\"bin_label\",\n",
    "#             features_col=self.featuresCol,\n",
    "#             prediction_col=self.clfPredictionCol\n",
    "#         )\n",
    "\n",
    "#         clfModel = clf.fit(df_ambig)\n",
    "\n",
    "#         return IntervalClassifierModel(\n",
    "#             lowerModel=lowerModel,\n",
    "#             upperModel=upperModel,\n",
    "#             clfModel=clfModel,\n",
    "#             labelCol=self.labelCol,\n",
    "#             featuresCol=self.featuresCol,\n",
    "#             predictionCol=self.predictionCol,\n",
    "#             threshold=self.threshold,\n",
    "#             qLowCol=self.qLowCol,\n",
    "#             qHighCol=self.qHighCol,\n",
    "#             clfPredictionCol=self.clfPredictionCol\n",
    "#         )\n",
    "\n",
    "# class IntervalClassifierModel(Model, DefaultParamsReadable, DefaultParamsWritable):\n",
    "\n",
    "#     def __init__(self,\n",
    "#                  lowerModel,\n",
    "#                  upperModel,\n",
    "#                  clfModel,\n",
    "#                  labelCol,\n",
    "#                  featuresCol,\n",
    "#                  predictionCol,\n",
    "#                  threshold,\n",
    "#                  qLowCol,\n",
    "#                  qHighCol,\n",
    "#                  clfPredictionCol):\n",
    "#         super().__init__()\n",
    "#         self.lowerModel = lowerModel\n",
    "#         self.upperModel = upperModel\n",
    "#         self.clfModel = clfModel\n",
    "#         self.labelCol = labelCol\n",
    "#         self.featuresCol = featuresCol\n",
    "#         self.predictionCol = predictionCol\n",
    "#         self.threshold = float(threshold)\n",
    "#         self.qLowCol = qLowCol\n",
    "#         self.qHighCol = qHighCol\n",
    "#         self.clfPredictionCol = clfPredictionCol\n",
    "\n",
    "#     def _transform(self, dataset: DataFrame) -> DataFrame:\n",
    "#         # 1) Predict quantiles\n",
    "#         df_q = self.lowerModel.transform(dataset) \\\n",
    "#                               .withColumnRenamed(\"prediction\", self.qLowCol)\n",
    "\n",
    "#         df_q = self.upperModel.transform(df_q) \\\n",
    "#                               .withColumnRenamed(\"prediction\", self.qHighCol)\n",
    "\n",
    "#         # 2) Get classifier predictions (on all rows, cheap and simple)\n",
    "#         print(\"Classifying **all** points with stage 2 classifier...\")\n",
    "#         # NOTE: make sure that if you change clfModel, you still have a .transform method or some equivalent\n",
    "#         df_clf = self.clfModel.transform(df_q)\n",
    "\n",
    "#         thr = lit(self.threshold)\n",
    "\n",
    "#         # Assume classifier is a binary classifier with predictions 0/1\n",
    "#         # Override classifier predictions where interval says we are confident.\n",
    "#         print(\"Classifying points with ambiguous predictions...\")\n",
    "#         df_final = df_clf.withColumn(\n",
    "#             self.predictionCol,\n",
    "#             when(thr < col(self.qLowCol), lit(1.0))      # confidently ≥ threshold\n",
    "#             .when(thr > col(self.qHighCol), lit(0.0))     # confidently < threshold\n",
    "#             .otherwise(col(self.clfPredictionCol))      # ambiguous → use classifier\n",
    "#         )\n",
    "\n",
    "#         # Strategy column to debug\n",
    "#         df_final = df_final.withColumn(\n",
    "#             \"decision_source\",\n",
    "#             when(thr < col(self.qLowCol), lit(\"quantile_high\"))\n",
    "#             .when(thr > col(self.qHighCol), lit(\"quantile_low\"))\n",
    "#             .otherwise(lit(\"classifier\"))\n",
    "#         )\n",
    "\n",
    "#         return df_final\n",
    "\n",
    "def deduplicate_cols(df):\n",
    "    unique_cols = []\n",
    "    seen = set()\n",
    "    for col_name in df.columns:\n",
    "        if col_name not in seen:\n",
    "            unique_cols.append(col_name)\n",
    "            seen.add(col_name)\n",
    "    df = df.select(unique_cols)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06fa16c1-a344-469e-aca4-26f972599b0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "688cfa43-b780-451f-b18a-a36522496d8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def checkpoint_dataset(dataset, file_path):\n",
    "    # Create base folder\n",
    "    section = \"2\"\n",
    "    number = \"2\"\n",
    "    base_folder = f\"dbfs:/student-groups/Group_{section}_{number}\"\n",
    "    dbutils.fs.mkdirs(base_folder)\n",
    "    # Create subfolders if file_path contains directories\n",
    "    full_path = f\"{base_folder}/{file_path}.parquet\"\n",
    "    subfolder = \"/\".join(full_path.split(\"/\")[:-1])\n",
    "    dbutils.fs.mkdirs(subfolder)\n",
    "    # Save dataset as a parquet file\n",
    "    dataset.write.mode(\"overwrite\").parquet(full_path)\n",
    "    print(f\"Checkpointed {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5421faa2-9cb0-474d-826d-8bf3c99d904a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Baseline 5-year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d7b274b-c8d2-4949-9a8a-2b58e6a17564",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls dbfs:/student-groups/Group_2_2/1_year_custom_joined/fe_graph_and_holiday/training_splits/test.parquet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86a4bf59-6a2c-4c61-bdb7-02fc93b051a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "MONTH_OR_YEAR = \"5_year_custom_joined\"\n",
    "\n",
    "train_df = spark.read.parquet(f\"dbfs:/student-groups/Group_2_2/{MONTH_OR_YEAR}/fe_graph_and_holiday/training_splits/train.parquet/\")\n",
    "validation_df = spark.read.parquet(f\"dbfs:/student-groups/Group_2_2/{MONTH_OR_YEAR}/fe_graph_and_holiday/training_splits/validation.parquet/\")\n",
    "test_df = spark.read.parquet(f\"dbfs:/student-groups/Group_2_2/{MONTH_OR_YEAR}/fe_graph_and_holiday/training_splits/test.parquet/\")\n",
    "\n",
    "# train_df = deduplicate_cols(train_df)\n",
    "# validation_df = deduplicate_cols(validation_df)\n",
    "# test_df = deduplicate_cols(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f14a671a-d2dd-4744-aaf9-2063b2925d9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df.columns == test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e848478a-d2a6-4fab-aa1d-df29e5848c57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1263f323-d1df-4baf-867a-f84ab4d90b8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "test_df = test_df.withColumn(\"year\", year(\"utc_timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80d32436-d34e-46ae-86c8-1a4b90758ebf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_cols = test_df.columns\n",
    "for column in train_cols:\n",
    "    if column not in test_cols:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bbc2fdc-ca7c-4815-92ce-ed6f69f3b344",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_dataset(test_df, f\"{MONTH_OR_YEAR}/fe_graph_and_holiday/training_splits/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4825eb9-9441-4e5d-a2c3-6adc6cea10cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19c74252-e81f-45d4-a5e9-e9204a73f356",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "baseline_columns = [\"QUARTER\", \"MONTH\", \"YEAR\", \"DAY_OF_MONTH\", \"DAY_OF_WEEK\", \"OP_CARRIER\", \"ORIGIN_AIRPORT_SEQ_ID\", \"DEST_AIRPORT_SEQ_ID\", \"CRS_ELAPSED_TIME\", \"DISTANCE\", \"DEP_DELAY_NEW\"]\n",
    "\n",
    "weather_columns = ['HourlyDryBulbTemperature', 'HourlyDewPointTemperature', 'HourlyRelativeHumidity', 'HourlyAltimeterSetting', 'HourlyVisibility', 'HourlyStationPressure', 'HourlyWetBulbTemperature', 'HourlyPrecipitation', 'HourlyCloudCoverage', 'HourlyCloudElevation', 'HourlyWindSpeed']\n",
    "\n",
    "graph_columns = ['page_rank', 'out_degree', 'in_degree', 'weighted_out_degree', 'weighted_in_degree', 'N_RUNWAYS', 'betweenness_unweighted', 'closeness', 'betweenness', 'avg_origin_dep_delay', 'avg_dest_arr_delay', 'avg_daily_route_flights', 'avg_route_delay', 'avg_hourly_flights']\n",
    "\n",
    "engineered_features = [\"CRS_DEP_MINUTES\", \"prev_flight_delay_in_minutes\", \"prev_flight_delay\", \"origin_delays_4h\", \"delay_origin_7d\", \"delay_origin_carrier_7d\", \"delay_route_7d\", \"flight_count_24h\", \"LANDING_TIME_DIFF_MINUTES\", \"AVG_ARR_DELAY_ORIGIN\", \"AVG_TAXI_OUT_ORIGIN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7ff4688-854e-4a7f-9429-b74fdc925f0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "# Categorical encoding\n",
    "carrier_indexer = StringIndexer(inputCol=\"OP_CARRIER\", outputCol=\"carrier_idx\", handleInvalid=\"keep\")\n",
    "origin_indexer = StringIndexer(inputCol=\"ORIGIN_AIRPORT_SEQ_ID\", outputCol=\"origin_idx\", handleInvalid=\"keep\")\n",
    "dest_indexer = StringIndexer(inputCol=\"DEST_AIRPORT_SEQ_ID\", outputCol=\"dest_idx\", handleInvalid=\"keep\")\n",
    "tail_num_indexer = StringIndexer(inputCol=\"TAIL_NUM\", outputCol=\"tail_num_idx\", handleInvalid=\"keep\")\n",
    "\n",
    "carrier_encoder = OneHotEncoder(inputCol=\"carrier_idx\", outputCol=\"carrier_vec\")\n",
    "origin_encoder = OneHotEncoder(inputCol=\"origin_idx\", outputCol=\"origin_vec\")\n",
    "dest_encoder = OneHotEncoder(inputCol=\"dest_idx\", outputCol=\"dest_vec\")\n",
    "tail_num_encoder = OneHotEncoder(inputCol=\"tail_num_idx\", outputCol=\"tail_num_vec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdde39db-852d-4ce5-882d-a3f7f7cf3f86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assemble all features\n",
    "transformed_baseline = [\n",
    "        \"QUARTER\",\n",
    "        \"MONTH\", \n",
    "        \"YEAR\",\n",
    "        \"DAY_OF_MONTH\",\n",
    "        \"DAY_OF_WEEK\",\n",
    "        \"carrier_vec\",\n",
    "        \"origin_vec\",\n",
    "        \"dest_vec\",\n",
    "        \"CRS_ELAPSED_TIME\",\n",
    "        \"DISTANCE\",\n",
    "    ]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=transformed_baseline,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "train_columns = baseline_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddc63097-8c00-4059-b7c1-678c9ab99ff6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\n",
    "from xgboost.spark import SparkXGBRegressor, SparkXGBClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "rmse_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"DEP_DELAY_NEW\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\" \n",
    ")\n",
    "\n",
    "mae_evaluator = RegressionEvaluator(\n",
    "        labelCol=\"DEP_DELAY_NEW\",      \n",
    "        predictionCol=\"prediction\", \n",
    "        metricName=\"mae\"    \n",
    ")\n",
    "\n",
    "\n",
    "xgb = SparkXGBRegressor(\n",
    "    features_col=\"features\",\n",
    "    label_col=\"DEP_DELAY_NEW\",\n",
    "    device='cpu',\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    num_workers=4,\n",
    "    # REDUCE MEMORY PRESSURE\n",
    "    tree_method='hist',\n",
    "    max_bin=128,  # Reduced from 256\n",
    "    subsample=0.6,  # Reduced from 0.8\n",
    "    colsample_bytree=0.6,  # Reduced from 0.8\n",
    "    # Limit parallelism per worker\n",
    "    # nthread=1,\n",
    "    # Add these for stability\n",
    "    use_gpu=False,\n",
    "    missing=np.nan\n",
    ")\n",
    "\n",
    "\n",
    "# --- Model Estimators ---\n",
    "preprocessing_stages = [\n",
    "    carrier_indexer, origin_indexer, dest_indexer, \n",
    "    carrier_encoder, origin_encoder, dest_encoder, \n",
    "    assembler \n",
    "]\n",
    "pipeline = Pipeline(stages=preprocessing_stages + [xgb])\n",
    "\n",
    "with mlflow.start_run(run_name=\"Ankush-XGB-5-YEAR-BASELINE\"):\n",
    "    MODEL_NAME = \"ANKUSH_XGB_5_YEAR_BASELINE\"\n",
    "\n",
    "    print(\"Training pipeline model...\")\n",
    "    model = pipeline.fit(train_df.select(train_columns))\n",
    "\n",
    "    print(\"Generating Training Predictions...\")\n",
    "    training_predictions = model.transform(train_df.select(train_columns))\n",
    "    print(\"Generating Validation Predictions...\")\n",
    "    validation_predictions = model.transform(validation_df.select(train_columns))\n",
    "    print(\"Generating Test Predictions...\")\n",
    "    test_predictions = model.transform(test_df.select(train_columns))\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae_train = mae_evaluator.evaluate(training_predictions)\n",
    "    mae_val = mae_evaluator.evaluate(validation_predictions)\n",
    "    mae_test = mae_evaluator.evaluate(test_predictions)\n",
    "    # Calculate RMSE\n",
    "    rmse_train = rmse_evaluator.evaluate(training_predictions)\n",
    "    rmse_val = rmse_evaluator.evaluate(validation_predictions)\n",
    "    rmse_test = rmse_evaluator.evaluate(test_predictions)\n",
    "\n",
    "    mlflow.log_metric(\"train_mae\", mae_train)\n",
    "    mlflow.log_metric(\"validation_mae\", mae_val)\n",
    "    mlflow.log_metric(\"test_mae\", mae_test)\n",
    "    mlflow.log_metric(\"train_rmse\", rmse_train)\n",
    "    mlflow.log_metric(\"validation_rmse\", rmse_val)\n",
    "    mlflow.log_metric(\"test_rmse\", rmse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9d06243-3e08-4f4b-9f0c-1579cfdd47a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# print(\"Creating binary label columns for evaluation...\")\n",
    "# def with_binary_label(df, label_col=\"DEP_DELAY_NEW\", out_col=\"label_bin\", threshold=DELAY_THRESHOLD):\n",
    "#     return df.withColumn(out_col, (col(label_col) >= lit(threshold)).cast(\"double\"))\n",
    "\n",
    "# training_predictions = with_binary_label(training_predictions)\n",
    "# validation_predictions = with_binary_label(validation_predictions)\n",
    "# test_predictions = with_binary_label(test_predictions)\n",
    "\n",
    "# f2_eval = MulticlassClassificationEvaluator(\n",
    "#             labelCol=\"label_bin\",\n",
    "#             predictionCol=\"final_prediction\",\n",
    "#             metricName=\"fMeasureByLabel\"   # requires setting beta below\n",
    "#         ).setMetricLabel(1).setBeta(2.0)    # evaluate F2 for the positive class (label=1)\n",
    "\n",
    "# f2_t = f2_eval.evaluate(training_predictions)\n",
    "# f2_v = f2_eval.evaluate(validation_predictions)\n",
    "# f2_test = f2_eval.evaluate(test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a238d70-baa5-4ae6-8cc0-aca0c2717655",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %python\n",
    "\n",
    "\n",
    "# use best hyperparameters from Phase 2\n",
    "# NOTE: This is the meat of what we will need to adjust through our hyperparameter tuning and model debugging. Don't run this cell, but feel free to use this as a sandbox to change around parameters/model definitions etc. Make sure that if one of the model objects below is called elsewhere in the \n",
    "\n",
    "# high_quantile, low_quantile = 0.95, 0.5\n",
    "# train_columns = baseline_columns\n",
    "\n",
    "\n",
    "# # Set num_workers to match your cluster\n",
    "# NUM_WORKERS = 8  # Your current cluster size\n",
    "\n",
    "# high_quantile, low_quantile = 0.95, 0.5\n",
    "\n",
    "# xgb_regressor_high = SparkXGBRegressor(\n",
    "#     objective=\"reg:quantileerror\",\n",
    "#     quantile_alpha=high_quantile,\n",
    "#     features_col=\"features\",\n",
    "#     label_col=\"DEP_DELAY_NEW\",\n",
    "#     num_workers=NUM_WORKERS,\n",
    "#     max_depth=6,\n",
    "#     n_estimators=100,\n",
    "#     learning_rate=0.05,\n",
    "#     device='cpu',\n",
    "#     num_round=200\n",
    "# )\n",
    "\n",
    "# xgb_regressor_low = SparkXGBRegressor(\n",
    "#     objective=\"reg:quantileerror\",\n",
    "#     quantile_alpha=low_quantile,\n",
    "#     features_col=\"features\",\n",
    "#     label_col=\"DEP_DELAY_NEW\",\n",
    "#     num_workers=NUM_WORKERS,\n",
    "#     max_depth=6,\n",
    "#     n_estimators=100,\n",
    "#     learning_rate=0.05,\n",
    "#     device='cpu',\n",
    "#     num_round=200\n",
    "# )\n",
    "\n",
    "# classifier = SparkXGBClassifier(\n",
    "#     features_col=\"features\",\n",
    "#     label_col=\"bin_label\",\n",
    "#     prediction_col=\"clf_prediction\",\n",
    "#     max_depth=6,\n",
    "#     n_estimators=100,\n",
    "#     learning_rate=0.05,\n",
    "#     num_workers=NUM_WORKERS,\n",
    "#     device='cpu',\n",
    "#     num_round=200\n",
    "# )\n",
    "\n",
    "# # Example classifier\n",
    "# # NOTE: This will need to be tuned once we have selected optimal low_quantile/high_quantile values\n",
    "# # NOTE: This xgb classifier may not be the best model type for our use case, please feel free to try others\n",
    "# # NOTE: Once we select a low_quantile/high_quantile, you can train those again and save the ambiguous training examples to further fine tune the classifier. This will help in model selection and narrowing our hyperparameter/model grid search, but eventually we will need to perform hyperparameter tuning on the entire pipeline end-to-end with no modular training/eval.\n",
    "\n",
    "\n",
    "# print(\"Initializing interval classifier...\")\n",
    "# interval_clf = IntervalClassifier(\n",
    "#     lowerEstimator=xgb_regressor_low,\n",
    "#     upperEstimator=xgb_regressor_high,\n",
    "#     baseClassifier=classifier,\n",
    "#     labelCol=\"DEP_DELAY_NEW\",\n",
    "#     featuresCol=\"features\",\n",
    "#     threshold=15.0,\n",
    "#     predictionCol=\"final_prediction\"\n",
    "# )\n",
    "\n",
    "# print(\"Building pipeline...\")\n",
    "# pipeline = Pipeline(stages=[carrier_indexer, origin_indexer, dest_indexer, \n",
    "#     carrier_encoder, origin_encoder, dest_encoder, \n",
    "#     assembler,\n",
    "#     interval_clf\n",
    "# ])\n",
    "\n",
    "# DELAY_THRESHOLD = 15.0  # minutes\n",
    "\n",
    "# metrics_dict = {\n",
    "#     \"f2_train\": f2_eval.evaluate(training_predictions),\n",
    "#     \"f2_val\": f2_eval.evaluate(validation_predictions),\n",
    "#     \"f2_test\": f2_eval.evaluate(test_predictions)\n",
    "# }\n",
    "# display(metrics_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "908be680-957b-4d2b-8686-885a8ad21550",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Didn't run the HP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f2e3116-3f08-4b5b-ac61-f64ea4f5e339",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with CV for XGBoost - OPTIMIZED\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "alg = 'XGB'\n",
    "n_folds = 5  # CHANGE 1: Reduced from 10 to 5 for 2x speedup\n",
    "month_or_year = \"1_year_custom_joined\"\n",
    "\n",
    "mae_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"DEP_DELAY_NEW\",      \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"mae\"           \n",
    ")\n",
    "\n",
    "rmse_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"DEP_DELAY_NEW\",      \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "# Store results for all hyperparameter combinations\n",
    "hyperparam_results = []\n",
    "\n",
    "# Parent run for entire hyperparameter tuning experiment\n",
    "with mlflow.start_run(run_name=\"XGB_HPTUNE_WITH_CV_1_YEAR\") as hptune_parent_run:\n",
    "    mlflow.log_param(\"algorithm\", \"XGBoost\")\n",
    "    mlflow.log_param(\"n_folds\", n_folds)\n",
    "    mlflow.log_param(\"dataset\", month_or_year)\n",
    "    mlflow.log_param(\"n_param_combinations\", len(xgb_grid))\n",
    "    \n",
    "    # Iterate through each hyperparameter combination\n",
    "    for param_idx, params_ in enumerate(xgb_grid):\n",
    "        estimator_with_params = xgb.copy(params_)\n",
    "        pipeline = Pipeline(stages=preprocessing_stages + [estimator_with_params])\n",
    "        \n",
    "        param_str = \"_\".join([f\"{p.name}_{params_[p]}\" for p in params_])\n",
    "        \n",
    "        # Child run for each hyperparameter combination\n",
    "        with mlflow.start_run(run_name=f\"params_{param_idx+1}_{param_str}\", nested=True) as param_run:\n",
    "            \n",
    "            # Log hyperparameters for this combination\n",
    "            mlflow.log_param(\"max_depth\", params_[xgb.max_depth])\n",
    "            mlflow.log_param(\"n_estimators\", params_[xgb.n_estimators])\n",
    "            mlflow.log_param(\"learning_rate\", params_[xgb.learning_rate])\n",
    "            \n",
    "            cv_results = []\n",
    "            fold_metrics = {\n",
    "                'train_mae': [], 'val_mae': [],\n",
    "                'train_rmse': [], 'val_rmse': []\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n{'='*120}\")\n",
    "            print(f\"Hyperparameter Combination {param_idx+1}/{len(xgb_grid)}: {param_str}\")\n",
    "            print(f\"{'='*120}\\n\")\n",
    "            \n",
    "            # CV loop for this hyperparameter combination\n",
    "            for fold_id in range(1, n_folds + 1):\n",
    "                # Nested run for each fold (nested within the param run)\n",
    "                with mlflow.start_run(run_name=f\"fold_{fold_id}\", nested=True) as fold_run:\n",
    "                    \n",
    "                    # CHANGE 2: Cache data for speed\n",
    "                    fold_train = read_specific_fold(\n",
    "                        path=f\"dbfs:/student-groups/Group_2_2/{month_or_year}/cv_splits\", \n",
    "                        fold_id=fold_id, \n",
    "                        split_type=\"train\"\n",
    "                    ).cache()\n",
    "                    \n",
    "                    fold_val = read_specific_fold(\n",
    "                        path=f\"dbfs:/student-groups/Group_2_2/{month_or_year}/cv_splits\", \n",
    "                        fold_id=fold_id, \n",
    "                        split_type=\"validation\"\n",
    "                    ).cache()\n",
    "                    \n",
    "                    # Materialize cache with single count\n",
    "                    fold_train.count()\n",
    "                    fold_val.count()\n",
    "                    \n",
    "                    print(f\"Training fold {fold_id}/{n_folds}...\")\n",
    "                    \n",
    "                    # Train model\n",
    "                    model = pipeline.fit(fold_train)\n",
    "                    \n",
    "                    # Make predictions (keeping both train and val)\n",
    "                    training_predictions = model.transform(fold_train)\n",
    "                    validation_predictions = model.transform(fold_val)\n",
    "                    \n",
    "                    # Evaluate\n",
    "                    mae_t = mae_evaluator.evaluate(training_predictions)\n",
    "                    mae_v = mae_evaluator.evaluate(validation_predictions)\n",
    "                    rmse_t = rmse_evaluator.evaluate(training_predictions)\n",
    "                    rmse_v = rmse_evaluator.evaluate(validation_predictions)\n",
    "                    \n",
    "                    fold_metrics['train_mae'].append(mae_t)\n",
    "                    fold_metrics['val_mae'].append(mae_v)\n",
    "                    fold_metrics['train_rmse'].append(rmse_t)\n",
    "                    fold_metrics['val_rmse'].append(rmse_v)\n",
    "                    \n",
    "                    # Log to fold run\n",
    "                    mlflow.log_metrics({\n",
    "                        \"train_mae\": mae_t,\n",
    "                        \"val_mae\": mae_v,\n",
    "                        \"train_rmse\": rmse_t,\n",
    "                        \"val_rmse\": rmse_v,\n",
    "                    })\n",
    "                    \n",
    "                    cv_results.append({\n",
    "                        'fold': fold_id,\n",
    "                        'train_mae': mae_t,\n",
    "                        'val_mae': mae_v,\n",
    "                        'train_rmse': rmse_t,\n",
    "                        'val_rmse': rmse_v\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"Fold {fold_id} - Train MAE: {mae_t:.4f}, Val MAE: {mae_v:.4f}\")\n",
    "                    \n",
    "                    # CHANGE 3: Unpersist cache after fold completes\n",
    "                    fold_train.unpersist()\n",
    "                    fold_val.unpersist()\n",
    "                \n",
    "                # Log fold metrics to param run (after fold run closes)\n",
    "                mlflow.log_metrics({\n",
    "                    f\"fold_{fold_id}_train_mae\": mae_t,\n",
    "                    f\"fold_{fold_id}_val_mae\": mae_v,\n",
    "                    f\"fold_{fold_id}_train_rmse\": rmse_t,\n",
    "                    f\"fold_{fold_id}_val_rmse\": rmse_v,\n",
    "                })\n",
    "            \n",
    "            # Calculate and log aggregated CV metrics for this param combination\n",
    "            avg_metrics = {\n",
    "                \"avg_train_mae\": np.mean(fold_metrics['train_mae']),\n",
    "                \"avg_val_mae\": np.mean(fold_metrics['val_mae']),\n",
    "                \"std_val_mae\": np.std(fold_metrics['val_mae']),\n",
    "                \"avg_train_rmse\": np.mean(fold_metrics['train_rmse']),\n",
    "                \"avg_val_rmse\": np.mean(fold_metrics['val_rmse']),\n",
    "                \"std_val_rmse\": np.std(fold_metrics['val_rmse'])\n",
    "            }\n",
    "            mlflow.log_metrics(avg_metrics)\n",
    "            \n",
    "            # Log CV results table\n",
    "            results_df = pd.DataFrame(cv_results)\n",
    "            mlflow.log_table(data=results_df, artifact_file=\"cv_fold_results.json\")\n",
    "            \n",
    "            # Store results for comparison across all param combinations\n",
    "            hyperparam_results.append({\n",
    "                'param_idx': param_idx + 1,\n",
    "                'max_depth': params_[xgb.max_depth],\n",
    "                'n_estimators': params_[xgb.n_estimators],\n",
    "                'learning_rate': params_[xgb.learning_rate],\n",
    "                'avg_train_mae': avg_metrics['avg_train_mae'],\n",
    "                'avg_val_mae': avg_metrics['avg_val_mae'],\n",
    "                'std_val_mae': avg_metrics['std_val_mae'],\n",
    "                'avg_train_rmse': avg_metrics['avg_train_rmse'],\n",
    "                'avg_val_rmse': avg_metrics['avg_val_rmse'],\n",
    "                'std_val_rmse': avg_metrics['std_val_rmse']\n",
    "            })\n",
    "            \n",
    "            print(f\"\\nParam Combo {param_idx+1} Complete - Avg Val MAE: {avg_metrics['avg_val_mae']:.4f} ± {avg_metrics['std_val_mae']:.4f}\")\n",
    "            print(f\"{'='*120}\\n\")\n",
    "    \n",
    "    # Log summary of all hyperparameter combinations\n",
    "    hyperparam_df = pd.DataFrame(hyperparam_results)\n",
    "    mlflow.log_table(data=hyperparam_df, artifact_file=\"hyperparam_comparison.json\")\n",
    "    \n",
    "    # Find and log best parameters\n",
    "    best_idx = hyperparam_df['avg_val_mae'].idxmin()\n",
    "    best_params = hyperparam_df.iloc[best_idx]\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        \"best_avg_val_mae\": best_params['avg_val_mae'],\n",
    "        \"best_std_val_mae\": best_params['std_val_mae'],\n",
    "    })\n",
    "    \n",
    "    mlflow.log_params({\n",
    "        \"best_max_depth\": best_params['max_depth'],\n",
    "        \"best_n_estimators\": best_params['n_estimators'],\n",
    "        \"best_learning_rate\": best_params['learning_rate'],\n",
    "    })\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*120)\n",
    "    print(\"HYPERPARAMETER TUNING COMPLETE\")\n",
    "    print(\"=\"*120)\n",
    "    print(\"\\nAll Parameter Combinations:\")\n",
    "    print(hyperparam_df.to_string(index=False))\n",
    "    print(f\"\\nBest Parameters (by Val MAE):\")\n",
    "    print(f\"  max_depth: {best_params['max_depth']}\")\n",
    "    print(f\"  n_estimators: {best_params['n_estimators']}\")\n",
    "    print(f\"  learning_rate: {best_params['learning_rate']}\")\n",
    "    print(f\"  Avg Val MAE: {best_params['avg_val_mae']:.4f} ± {best_params['std_val_mae']:.4f}\")\n",
    "    print(\"=\"*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b59bc036-2de1-46fd-9d01-bcd2cd04dab9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# hyperparam_xgb_df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4093368127199627,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Phase_3_modeling_training",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
