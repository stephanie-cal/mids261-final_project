{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25d6a5ac-8bbf-47d4-822e-27b3f1b35460",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# XGBOOST model baseline - 1 year\n",
    "- run model from 1_year_combined data with feature engineering\n",
    "  - TAIL_NUM causes OOM error, comment out for now\n",
    "- featuring engineering handled in https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/1792055957780055?o=4021782157704243\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46f0190e-ca20-42f1-a87e-a3db6d8ecc04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "466c9b79-14bf-4db7-906c-23b1354bd52f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import mlflow\n",
    "print(mlflow.__version__)\n",
    "\n",
    "import os\n",
    "\n",
    "spark.conf.set(\"spark.databricks.mlflow.trackMLlib.enabled\", \"true\")\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "# Define experiment name with proper Databricks path\n",
    "EXPERIMENT_NAME = \"/Shared/team_2_2/mlflow-2-stage-dev\"\n",
    "# Create the experiment if it doesn't exist\n",
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if experiment is None:\n",
    "        experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "        print(f\"Created new experiment with ID: {experiment_id}\")\n",
    "    else:\n",
    "        print(f\"Using existing experiment: {experiment.name}\")\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "except Exception as e:\n",
    "    print(f\"Error with experiment setup: {e}\")\n",
    "    # Fallback to default experiment in workspace\n",
    "    mlflow.set_experiment(f\"/Users/{dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()}/default\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06fa16c1-a344-469e-aca4-26f972599b0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "688cfa43-b780-451f-b18a-a36522496d8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def checkpoint_dataset(dataset, file_path):\n",
    "    # Create base folder\n",
    "    section = \"2\"\n",
    "    number = \"2\"\n",
    "    base_folder = f\"dbfs:/student-groups/Group_{section}_{number}\"\n",
    "    dbutils.fs.mkdirs(base_folder)\n",
    "    # Create subfolders if file_path contains directories\n",
    "    full_path = f\"{base_folder}/{file_path}.parquet\"\n",
    "    subfolder = \"/\".join(full_path.split(\"/\")[:-1])\n",
    "    dbutils.fs.mkdirs(subfolder)\n",
    "    # Save dataset as a parquet file\n",
    "    dataset.write.mode(\"overwrite\").parquet(full_path)\n",
    "    print(f\"Checkpointed {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "128ec4a2-9ea7-4229-b0f4-794a0f63cc30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Datasets - custom join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d7b274b-c8d2-4949-9a8a-2b58e6a17564",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls dbfs:/student-groups/Group_2_2/3_month_custom_joined/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6d6f9c3-47ea-4ff0-8ed4-67f891e00385",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = f\"dbfs:/student-groups/Group_2_2\"\n",
    "# dataset_path = f\"{checkpoint_path}/1_year_custom_joined/raw_data/training_splits\"\n",
    "dataset_path = f\"{checkpoint_path}/3_month_custom_joined/feature_eng/training_splits\"\n",
    "\n",
    "# Read datasets from checkpoint\n",
    "train_df = spark.read.parquet(f\"{dataset_path}/train.parquet\")\n",
    "validation_df = spark.read.parquet(f\"{dataset_path}/validation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddfff3a4-3d6e-4760-9ca5-4b17b97eb60e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orig_train_df_size = train_df.count()\n",
    "orig_validation_df_size = validation_df.count()\n",
    "print(f\"Size of train_df: {orig_train_df_size}\")\n",
    "print(f\"Size of validation_df: {orig_validation_df_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4825eb9-9441-4e5d-a2c3-6adc6cea10cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e71052af-525f-4775-a2cc-79142b51f875",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "baselines_columns = [\n",
    "    \"QUARTER\",\n",
    "    \"MONTH\",\n",
    "    \"YEAR\",\n",
    "    \"DAY_OF_MONTH\",\n",
    "    \"DAY_OF_WEEK\",\n",
    "    \"OP_CARRIER\",\n",
    "    # \"TAIL_NUM\",\n",
    "    \"ORIGIN_AIRPORT_SEQ_ID\",\n",
    "    \"DEST_AIRPORT_SEQ_ID\",\n",
    "    \"CRS_ELAPSED_TIME\",\n",
    "    \"DISTANCE\",\n",
    "    \"DEP_DELAY_NEW\",\n",
    "    \"utc_timestamp\",\n",
    "    \"CRS_DEP_MINUTES\",            # feature eng start\n",
    "    \"prev_flight_delay_in_minutes\", \n",
    "    \"prev_flight_delay\",\n",
    "    \"origin_delays_4h\",\n",
    "    \"delay_origin_7d\",\n",
    "    \"delay_origin_carrier_7d\",\n",
    "    \"delay_route_7d\",\n",
    "    \"flight_count_24h\",\n",
    "    \"LANDING_TIME_DIFF_MINUTES\",\n",
    "    \"AVG_ARR_DELAY_ORIGIN\",\n",
    "    \"AVG_TAXI_OUT_ORIGIN\",        # feature eng end\n",
    "    'HourlyDryBulbTemperature',     # weather start\n",
    "    'HourlyDewPointTemperature',\n",
    "    'HourlyRelativeHumidity',\n",
    "    'HourlyAltimeterSetting',\n",
    "    'HourlyVisibility',\n",
    "    'HourlyStationPressure',\n",
    "    'HourlyWetBulbTemperature',\n",
    "    'HourlyPrecipitation',\n",
    "    'HourlyCloudCoverage',\n",
    "    'HourlyCloudElevation',\n",
    "    'HourlyWindSpeed'               # weather end\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79d9c263-ad93-4094-9f1d-45388954d17c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.filter(F.col(\"DEP_DELAY_NEW\").isNotNull()).select(baselines_columns)\n",
    "validation_df = validation_df.filter(F.col(\"DEP_DELAY_NEW\").isNotNull()).select(baselines_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c05329b-2c5c-4bac-aa0a-6e763bee7605",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Size of cleaned train_df: {train_df.count()}\")\n",
    "print(f\"Size of cleaned validation_df: {validation_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7ff4688-854e-4a7f-9429-b74fdc925f0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "# Categorical encoding\n",
    "carrier_indexer = StringIndexer(inputCol=\"OP_CARRIER\", outputCol=\"carrier_idx\", handleInvalid=\"keep\")\n",
    "origin_indexer = StringIndexer(inputCol=\"ORIGIN_AIRPORT_SEQ_ID\", outputCol=\"origin_idx\", handleInvalid=\"keep\")\n",
    "dest_indexer = StringIndexer(inputCol=\"DEST_AIRPORT_SEQ_ID\", outputCol=\"dest_idx\", handleInvalid=\"keep\")\n",
    "tail_num_indexer = StringIndexer(inputCol=\"TAIL_NUM\", outputCol=\"tail_num_idx\", handleInvalid=\"keep\")\n",
    "\n",
    "carrier_encoder = OneHotEncoder(inputCol=\"carrier_idx\", outputCol=\"carrier_vec\")\n",
    "origin_encoder = OneHotEncoder(inputCol=\"origin_idx\", outputCol=\"origin_vec\")\n",
    "dest_encoder = OneHotEncoder(inputCol=\"dest_idx\", outputCol=\"dest_vec\")\n",
    "tail_num_encoder = OneHotEncoder(inputCol=\"tail_num_idx\", outputCol=\"tail_num_vec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdde39db-852d-4ce5-882d-a3f7f7cf3f86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assemble all features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"QUARTER\",\n",
    "        \"MONTH\", \n",
    "        \"YEAR\",\n",
    "        \"DAY_OF_MONTH\",\n",
    "        \"DAY_OF_WEEK\",\n",
    "        \"carrier_vec\",\n",
    "        \"origin_vec\",\n",
    "        \"dest_vec\",\n",
    "        \"CRS_ELAPSED_TIME\",\n",
    "        \"DISTANCE\",\n",
    "        # \"tail_num_vec\",\n",
    "        \"CRS_DEP_MINUTES\",                 # feature eng start\n",
    "        \"prev_flight_delay_in_minutes\",\n",
    "        \"prev_flight_delay\",\n",
    "        \"origin_delays_4h\",\n",
    "        \"delay_origin_7d\",\n",
    "        \"delay_origin_carrier_7d\",\n",
    "        \"delay_route_7d\",\n",
    "        \"flight_count_24h\",\n",
    "        \"LANDING_TIME_DIFF_MINUTES\",\n",
    "        \"AVG_ARR_DELAY_ORIGIN\",\n",
    "        \"AVG_TAXI_OUT_ORIGIN\",              # feature eng end\n",
    "        'HourlyDryBulbTemperature',         # weather start\n",
    "        'HourlyDewPointTemperature',\n",
    "        'HourlyRelativeHumidity',\n",
    "        'HourlyAltimeterSetting',\n",
    "        'HourlyVisibility',\n",
    "        'HourlyStationPressure',\n",
    "        'HourlyWetBulbTemperature',\n",
    "        'HourlyPrecipitation',\n",
    "        'HourlyCloudCoverage',\n",
    "        'HourlyCloudElevation',\n",
    "        'HourlyWindSpeed'                   # weather end\n",
    "\n",
    "    ],\n",
    "    outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fec4455-ee64-415b-a54e-600691c42e99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2261bf73-37b9-4449-8bd0-445fd78d1659",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# baseline\n",
    "\"\"\"\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from xgboost.spark import SparkXGBRegressor\n",
    "\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "mlflow.spark.autolog()\n",
    "with mlflow.start_run(run_name=\"XGB-3m_2_stage_all_feat\"):\n",
    "    MODEL_NAME = \"XGB_3m_2_STAGE\"\n",
    "\n",
    "    # linear_reg = LinearRegression(\n",
    "    #     featuresCol=\"features\",\n",
    "    #     labelCol=\"DEP_DELAY_NEW\",\n",
    "    #     # Linear Regression has different parameters than Random Forest\n",
    "    #     maxIter=10, \n",
    "    #     regParam=0.3\n",
    "    # )\n",
    "    # rf = RandomForestRegressor(\n",
    "    #     featuresCol=\"features\",  \n",
    "    #     labelCol=\"DEP_DELAY_NEW\",   \n",
    "    #     numTrees=20,\n",
    "    #     maxDepth=10\n",
    "    # )\n",
    "\n",
    "    quantile_width = 0.1\n",
    "\n",
    "    xgb_regressor_high = SparkXGBRegressor(\n",
    "        objective=\"reg:quantileerror\",\n",
    "        quantile_alpha=1 - quantile_width,\n",
    "        num_round=200,\n",
    "        features_col=\"features\",\n",
    "        label_col=\"DEP_DELAY_NEW\",\n",
    "        num_workers=2,\n",
    "        max_depth=6,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.3\n",
    "    )\n",
    "\n",
    "    xgb_regressor_low = SparkXGBRegressor(\n",
    "        objective=\"reg:quantileerror\",\n",
    "        quantile_alpha=quantile_width,\n",
    "        num_round=200,\n",
    "        features_col=\"features\",\n",
    "        label_col=\"DEP_DELAY_NEW\",\n",
    "        num_workers=2,\n",
    "        max_depth=6,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.3\n",
    "    )\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline_high = Pipeline(stages=[\n",
    "        carrier_indexer, origin_indexer, dest_indexer, \n",
    "        carrier_encoder, origin_encoder, dest_encoder, \n",
    "        assembler,\n",
    "        # linear_reg\n",
    "        # rf\n",
    "        xgb_regressor_high\n",
    "    ])\n",
    "    # Create pipeline\n",
    "    pipeline_low = Pipeline(stages=[\n",
    "        carrier_indexer, origin_indexer, dest_indexer, \n",
    "        carrier_encoder, origin_encoder, dest_encoder, \n",
    "        assembler,\n",
    "        # linear_reg\n",
    "        # rf\n",
    "        xgb_regressor_low\n",
    "    ])\n",
    "\n",
    "    model_high = pipeline_high.fit(train_df)\n",
    "    training_predictions_high = model_high.transform(train_df)\n",
    "    validation_predictions_high = model_high.transform(validation_df)\n",
    "\n",
    "    model_low = pipeline_low.fit(train_df)\n",
    "    training_predictions_low = model_low.transform(train_df)\n",
    "    validation_predictions_low = model_low.transform(validation_df)\n",
    "\n",
    "    mae_evaluator = RegressionEvaluator(\n",
    "        labelCol=\"DEP_DELAY_NEW\",      \n",
    "        predictionCol=\"prediction\", \n",
    "        metricName=\"mae\"           \n",
    "    )\n",
    "\n",
    "    rmse_evaluator = RegressionEvaluator(\n",
    "        labelCol=\"DEP_DELAY_NEW\",      \n",
    "        predictionCol=\"prediction\", \n",
    "        metricName=\"rmse\"\n",
    "    )\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae_t_high = mae_evaluator.evaluate(training_predictions_high)\n",
    "    mae_v_high = mae_evaluator.evaluate(validation_predictions_high)\n",
    "    # Calculate RMSE\n",
    "    rmse_t_high = rmse_evaluator.evaluate(training_predictions_high)\n",
    "    rmse_v_high = rmse_evaluator.evaluate(validation_predictions_high)\n",
    "\n",
    "    signature_high = infer_signature(train_df, training_predictions_high)\n",
    "\n",
    "    mlflow.spark.log_model(\n",
    "        model_high, \n",
    "        f\"{MODEL_NAME}_high\",\n",
    "        input_example=train_df.limit(1).toPandas(),\n",
    "        signature=signature_high,\n",
    "        registered_model_name=\"2_stage_high_dev\"\n",
    "        )\n",
    "\n",
    "    mlflow.log_metric(\"train_mae\", mae_t_high)\n",
    "    mlflow.log_metric(\"validation_mae\", mae_v_high)\n",
    "    mlflow.log_metric(\"train_rmse\", rmse_t_high)\n",
    "    mlflow.log_metric(\"validation_rmse\", rmse_v_high)\n",
    "\n",
    "\n",
    "    # ----------- Low -------------\n",
    "    # Calculate MAE\n",
    "    mae_t_low = mae_evaluator.evaluate(training_predictions_low)\n",
    "    mae_v_low = mae_evaluator.evaluate(validation_predictions_low)\n",
    "    # Calculate RMSE\n",
    "    rmse_t_low = rmse_evaluator.evaluate(training_predictions_low)\n",
    "    rmse_v_low = rmse_evaluator.evaluate(validation_predictions_low)\n",
    "\n",
    "    signature_low = infer_signature(train_df, training_predictions_low)\n",
    "\n",
    "    mlflow.spark.log_model(\n",
    "        model_low, \n",
    "        f\"{MODEL_NAME}_low\",\n",
    "        input_example=train_df.limit(1).toPandas(),\n",
    "        signature=signature_low,\n",
    "        registered_model_name=\"2_stage_low_dev\"\n",
    "        )\n",
    "\n",
    "    mlflow.log_metric(\"train_mae\", mae_t_low)\n",
    "    mlflow.log_metric(\"validation_mae\", mae_v_low)\n",
    "    mlflow.log_metric(\"train_rmse\", rmse_t_low)\n",
    "    mlflow.log_metric(\"validation_rmse\", rmse_v_low)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "aaaaaa = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc20216a-d892-45d1-8042-3f13d3f2496b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fd97ac4-fb5c-4218-906c-1ca89499884f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Save best model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e732e7e-3b42-4296-85e1-5c3d78506174",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# best model information\n",
    "\"\"\"\n",
    "RUN_ID = \"100863169f14462fb514efa6483a170e\"\n",
    "ARTIFACT_PATH = \"XGB_1y_BASELINE_FEAT_ENG\"\n",
    "\n",
    "MODEL_URI = f\"runs:/{RUN_ID}/{ARTIFACT_PATH}\"\n",
    "# Load the model\n",
    "loaded_model = mlflow.spark.load_model(MODEL_URI)\n",
    "\"\"\"\n",
    "aaaaaaa = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdc2280f-e50b-4b3f-8e87-017ab06026b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2-Stage Modeling Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71adcbd5-61e2-4491-9846-c2138cd94ab1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Estimator, Model\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.sql.functions import col, lit, when\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import count as f_count\n",
    "\n",
    "class IntervalClassifier(Estimator, DefaultParamsReadable, DefaultParamsWritable):\n",
    "\n",
    "    def __init__(self,\n",
    "                 lowerEstimator,\n",
    "                 upperEstimator,\n",
    "                 baseClassifier,\n",
    "                 labelCol=\"delay_minutes\",\n",
    "                 featuresCol=\"features\",\n",
    "                 predictionCol=\"final_prediction\",\n",
    "                 threshold=15.0,\n",
    "                 quantile_gap=0.1,\n",
    "                 qLowCol=\"low_pred\",\n",
    "                 qHighCol=\"high_pred\",\n",
    "                 clfPredictionCol=\"clf_prediction\",\n",
    "                 undersample_majority=True,\n",
    "                 undersample_seed=42):\n",
    "        super().__init__()\n",
    "        self.lowerEstimator = lowerEstimator\n",
    "        self.upperEstimator = upperEstimator\n",
    "        self.baseClassifier = baseClassifier\n",
    "        self.labelCol = labelCol\n",
    "        self.featuresCol = featuresCol\n",
    "        self.predictionCol = predictionCol\n",
    "        self.threshold = float(threshold)\n",
    "        self.quantile_gap = float(quantile_gap)\n",
    "        self.qLowCol = qLowCol\n",
    "        self.qHighCol = qHighCol\n",
    "        self.clfPredictionCol = clfPredictionCol\n",
    "        self.undersample_majority = undersample_majority\n",
    "        self.undersample_seed = undersample_seed\n",
    "\n",
    "    def _fit(self, dataset: DataFrame) -> Model:\n",
    "        # 1) Fit quantile regressors on ALL data\n",
    "        print(\"Training Lower Estimator...\")\n",
    "        lowerModel = self.lowerEstimator.fit(dataset)\n",
    "        print(\"Training Upper Estimator...\")\n",
    "        upperModel = self.upperEstimator.fit(dataset)\n",
    "\n",
    "        print(\"Configuring Classifier...\")\n",
    "        # 2) Add qLow and qHigh predictions\n",
    "        df_q = lowerModel.transform(dataset) \\\n",
    "                         .withColumnRenamed(\"prediction\", self.qLowCol)\n",
    "\n",
    "        df_q = upperModel.transform(df_q) \\\n",
    "                         .withColumnRenamed(\"prediction\", self.qHighCol)\n",
    "\n",
    "        # 3) Keep only examples where 15 is between qLow and qHigh\n",
    "        print(\"Filtering ambiguous cases...\")\n",
    "        thr = lit(self.threshold)\n",
    "        df_ambig = df_q.filter(\n",
    "            (col(self.qLowCol) <= thr) & (thr <= col(self.qHighCol))\n",
    "        )\n",
    "\n",
    "        # 4) Build binary label: 1 if delay ≥ threshold, else 0\n",
    "        df_ambig = df_ambig.withColumn(\n",
    "            \"bin_label\",\n",
    "            (col(self.labelCol) >= thr).cast(\"double\")\n",
    "        )\n",
    "        print(\"Undersampling...\")\n",
    "        # --- undersample majority class among ambiguous cases ---\n",
    "        if self.undersample_majority:\n",
    "            # class counts on driver (only 2 classes)\n",
    "            class_counts = (\n",
    "                df_ambig.groupBy(\"bin_label\")\n",
    "                        .agg(f_count(\"*\").alias(\"cnt\"))\n",
    "                        .collect()\n",
    "            )\n",
    "\n",
    "            # If we have both classes, find minority/majority and undersample\n",
    "            if len(class_counts) != 2:\n",
    "                raise ValueError(\"Ambiguous cases must contain both classes.\")\n",
    "\n",
    "            (label0, cnt0), (label1, cnt1) = [\n",
    "                (row[\"bin_label\"], row[\"cnt\"]) for row in class_counts\n",
    "            ]\n",
    "\n",
    "            if cnt0 <= cnt1:\n",
    "                minority_label, minority_cnt = label0, cnt0\n",
    "                majority_label, majority_cnt = label1, cnt1\n",
    "            else:\n",
    "                minority_label, minority_cnt = label1, cnt1\n",
    "                majority_label, majority_cnt = label0, cnt0\n",
    "\n",
    "            print(f\"Undersampling majority class {majority_label} from {majority_cnt} to {minority_cnt}.\")\n",
    "\n",
    "            if majority_cnt > 0 and minority_cnt > 0:\n",
    "                frac_majority = float(minority_cnt) / float(majority_cnt)\n",
    "\n",
    "                # sampleBy keeps all minority, downsamples majority\n",
    "                fractions = {\n",
    "                    float(minority_label): 1.0,\n",
    "                    float(majority_label): frac_majority\n",
    "                }\n",
    "\n",
    "                df_ambig = df_ambig.sampleBy(\n",
    "                    \"bin_label\",\n",
    "                    fractions=fractions,\n",
    "                    seed=self.undersample_seed\n",
    "                )\n",
    "        # --- END undersampling block ---\n",
    "\n",
    "        print(\"Training Base Classifier...\")\n",
    "        # 5) Fit classifier on (possibly undersampled) ambiguous region\n",
    "        clf = self.baseClassifier\n",
    "        \n",
    "        clf.setParams(\n",
    "            label_col=\"bin_label\",\n",
    "            features_col=self.featuresCol,\n",
    "            prediction_col=self.clfPredictionCol\n",
    "        )\n",
    "\n",
    "        clfModel = clf.fit(df_ambig)\n",
    "\n",
    "        return IntervalClassifierModel(\n",
    "            lowerModel=lowerModel,\n",
    "            upperModel=upperModel,\n",
    "            clfModel=clfModel,\n",
    "            labelCol=self.labelCol,\n",
    "            featuresCol=self.featuresCol,\n",
    "            predictionCol=self.predictionCol,\n",
    "            threshold=self.threshold,\n",
    "            qLowCol=self.qLowCol,\n",
    "            qHighCol=self.qHighCol,\n",
    "            clfPredictionCol=self.clfPredictionCol\n",
    "        )\n",
    "\n",
    "class IntervalClassifierModel(Model, DefaultParamsReadable, DefaultParamsWritable):\n",
    "\n",
    "    def __init__(self,\n",
    "                 lowerModel,\n",
    "                 upperModel,\n",
    "                 clfModel,\n",
    "                 labelCol,\n",
    "                 featuresCol,\n",
    "                 predictionCol,\n",
    "                 threshold,\n",
    "                 qLowCol,\n",
    "                 qHighCol,\n",
    "                 clfPredictionCol):\n",
    "        super().__init__()\n",
    "        self.lowerModel = lowerModel\n",
    "        self.upperModel = upperModel\n",
    "        self.clfModel = clfModel\n",
    "        self.labelCol = labelCol\n",
    "        self.featuresCol = featuresCol\n",
    "        self.predictionCol = predictionCol\n",
    "        self.threshold = float(threshold)\n",
    "        self.qLowCol = qLowCol\n",
    "        self.qHighCol = qHighCol\n",
    "        self.clfPredictionCol = clfPredictionCol\n",
    "\n",
    "    def _transform(self, dataset: DataFrame) -> DataFrame:\n",
    "        # 1) Predict quantiles\n",
    "        df_q = self.lowerModel.transform(dataset) \\\n",
    "                              .withColumnRenamed(\"prediction\", self.qLowCol)\n",
    "\n",
    "        df_q = self.upperModel.transform(df_q) \\\n",
    "                              .withColumnRenamed(\"prediction\", self.qHighCol)\n",
    "\n",
    "        # 2) Get classifier predictions (on all rows, cheap and simple)\n",
    "        print(\"Classifying **all** points with stage 2 classifier...\")\n",
    "        df_clf = self.clfModel.transform(df_q)\n",
    "\n",
    "        thr = lit(self.threshold)\n",
    "\n",
    "        # Assume classifier is a binary classifier with predictions 0/1\n",
    "        # Override classifier predictions where interval says we are confident.\n",
    "        print(\"Classifying points with ambiguous predictions...\")\n",
    "        df_final = df_clf.withColumn(\n",
    "            self.predictionCol,\n",
    "            when(thr < col(self.qLowCol), lit(1.0))      # confidently ≥ threshold\n",
    "            .when(thr > col(self.qHighCol), lit(0.0))     # confidently < threshold\n",
    "            .otherwise(col(self.clfPredictionCol))      # ambiguous → use classifier\n",
    "        )\n",
    "\n",
    "        # Strategy column to debug\n",
    "        df_final = df_final.withColumn(\n",
    "            \"decision_source\",\n",
    "            when(thr < col(self.qLowCol), lit(\"quantile_high\"))\n",
    "            .when(thr > col(self.qHighCol), lit(\"quantile_low\"))\n",
    "            .otherwise(lit(\"classifier\"))\n",
    "        )\n",
    "\n",
    "        return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fcd8162-c5c5-4da0-ae46-d0ce6ca6bec6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "#from pyspark.ml.classification import RandomForestClassifier\n",
    "from xgboost.spark import SparkXGBRegressor, SparkXGBClassifier\n",
    "\n",
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "MODEL_NAME = \"XGB_3m_2_STAGE_dev\"\n",
    "print(\"Starting MLflow autolog setup...\")\n",
    "mlflow.spark.autolog()\n",
    "\n",
    "#high_quantiles = np.arange(0.75, 0.9, 0.025)\n",
    "high_quantiles = np.arange(0.98, 1, 0.005)\n",
    "low_quantiles = np.arange(0.24, 0.4, 0.02)\n",
    "\n",
    "for high_quantile in high_quantiles:\n",
    "    for low_quantile in low_quantiles:\n",
    "        run_name = f\"XGB-3m_2_stage_dev_low_{low_quantile:.3f}_high_{high_quantile:.3f}\"\n",
    "\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            print(f\"Starting MLflow run for {run_name}\")\n",
    "            print(\"Defining model parameters and estimators...\")\n",
    "\n",
    "            # use best hyperparameters from Phase 2\n",
    "            xgb_regressor_high = SparkXGBRegressor(\n",
    "                    objective=\"reg:quantileerror\",\n",
    "                    quantile_alpha=high_quantile,\n",
    "                    num_round=200,\n",
    "                    features_col=\"features\",\n",
    "                    label_col=\"DEP_DELAY_NEW\",\n",
    "                    num_workers=2,\n",
    "                    max_depth=6,\n",
    "                    n_estimators=100,\n",
    "                    learning_rate=0.05\n",
    "                )\n",
    "\n",
    "            xgb_regressor_low = SparkXGBRegressor(\n",
    "                objective=\"reg:quantileerror\",\n",
    "                quantile_alpha=low_quantile,\n",
    "                num_round=200,\n",
    "                features_col=\"features\",\n",
    "                label_col=\"DEP_DELAY_NEW\",\n",
    "                num_workers=2,\n",
    "                max_depth=6,\n",
    "                n_estimators=100,\n",
    "                learning_rate=0.05\n",
    "            )\n",
    "\n",
    "            max_depth = 6\n",
    "            n_estimators = 100\n",
    "            learning_rate = 0.05\n",
    "            num_round=200\n",
    "            # Example classifier\n",
    "            xgb_classifier = SparkXGBClassifier(\n",
    "                num_round=200,\n",
    "                features_col=\"features\",\n",
    "                label_col=\"bin_label\",\n",
    "                prediction_col=\"clf_prediction\",\n",
    "                max_depth=6,\n",
    "                n_estimators=100,\n",
    "                learning_rate=0.05,\n",
    "                num_workers=2\n",
    "            )\n",
    "\n",
    "            print(\"Initializing interval classifier...\")\n",
    "            interval_clf = IntervalClassifier(\n",
    "                lowerEstimator=xgb_regressor_low,\n",
    "                upperEstimator=xgb_regressor_high,\n",
    "                baseClassifier=xgb_classifier,\n",
    "                labelCol=\"DEP_DELAY_NEW\",\n",
    "                featuresCol=\"features\",\n",
    "                threshold=15.0,\n",
    "                predictionCol=\"final_prediction\"\n",
    "            )\n",
    "\n",
    "            print(\"Building pipeline...\")\n",
    "            pipeline = Pipeline(stages=[carrier_indexer, origin_indexer, dest_indexer, \n",
    "                carrier_encoder, origin_encoder, dest_encoder, \n",
    "                assembler,\n",
    "                interval_clf\n",
    "            ])\n",
    "\n",
    "            DELAY_THRESHOLD = 15.0  # minutes\n",
    "\n",
    "            print(\"Training pipeline model...\")\n",
    "            model = pipeline.fit(train_df)\n",
    "            print(\"Generating Training Predictions...\")\n",
    "            training_predictions = model.transform(train_df)\n",
    "            print(\"Generating Validation Predictions...\")\n",
    "            validation_predictions = model.transform(validation_df)\n",
    "\n",
    "            print(\"Creating binary label columns for evaluation...\")\n",
    "            def with_binary_label(df, label_col=\"DEP_DELAY_NEW\", out_col=\"label_bin\", threshold=DELAY_THRESHOLD):\n",
    "                return df.withColumn(out_col, (col(label_col) >= lit(threshold)).cast(\"double\"))\n",
    "\n",
    "            training_predictions = with_binary_label(training_predictions)\n",
    "            validation_predictions = with_binary_label(validation_predictions)\n",
    "\n",
    "            print(\"Setting up metric evaluators...\")\n",
    "            precision_eval = MulticlassClassificationEvaluator(\n",
    "                labelCol=\"label_bin\",\n",
    "                predictionCol=\"final_prediction\",\n",
    "                metricName=\"precisionByLabel\"\n",
    "            ).setMetricLabel(1)\n",
    "\n",
    "            recall_eval = MulticlassClassificationEvaluator(\n",
    "                labelCol=\"label_bin\",\n",
    "                predictionCol=\"final_prediction\",\n",
    "                metricName=\"recallByLabel\"\n",
    "            ).setMetricLabel(1)\n",
    "\n",
    "            f2_eval = MulticlassClassificationEvaluator(\n",
    "                labelCol=\"label_bin\",\n",
    "                predictionCol=\"final_prediction\",\n",
    "                metricName=\"fMeasureByLabel\"   # requires setting beta below\n",
    "            ).setMetricLabel(1).setBeta(2.0)    # evaluate F2 for the positive class (label=1)\n",
    "\n",
    "            pr_auc_eval = BinaryClassificationEvaluator(\n",
    "                labelCol=\"label_bin\",\n",
    "                rawPredictionCol=\"rawPrediction\",   # or probabilityCol=\"probability\"\n",
    "                metricName=\"areaUnderPR\"\n",
    "            )\n",
    "\n",
    "            print(\"Computing metrics...\")\n",
    "            precision_t = precision_eval.evaluate(training_predictions)\n",
    "            precision_v = precision_eval.evaluate(validation_predictions)\n",
    "\n",
    "            recall_t = recall_eval.evaluate(training_predictions)\n",
    "            recall_v = recall_eval.evaluate(validation_predictions)\n",
    "\n",
    "            f2_t = f2_eval.evaluate(training_predictions)\n",
    "            f2_v = f2_eval.evaluate(validation_predictions)\n",
    "\n",
    "            pr_auc_t = pr_auc_eval.evaluate(training_predictions)\n",
    "            pr_auc_v = pr_auc_eval.evaluate(validation_predictions)\n",
    "\n",
    "            # Classification Source Metrics\n",
    "\n",
    "            pos_prec_eval = MulticlassClassificationEvaluator(\n",
    "                labelCol=\"label_bin\",\n",
    "                predictionCol=\"final_prediction\",\n",
    "                metricName=\"precisionByLabel\"\n",
    "            ).setMetricLabel(1)\n",
    "\n",
    "            pos_rec_eval = MulticlassClassificationEvaluator(\n",
    "                labelCol=\"label_bin\",\n",
    "                predictionCol=\"final_prediction\",\n",
    "                metricName=\"recallByLabel\"\n",
    "            ).setMetricLabel(1)\n",
    "\n",
    "\n",
    "            beta = 2.0\n",
    "\n",
    "            for src in [\"quantile_low\", \"quantile_high\", \"classifier\"]:\n",
    "                seg = validation_predictions.filter(col(\"decision_source\") == src)\n",
    "\n",
    "                # basic counts\n",
    "                seg_count = seg.count()\n",
    "                mlflow.log_metric(f\"val_{src}_count\", seg_count)\n",
    "\n",
    "                if seg_count == 0:\n",
    "                    # nothing in this segment → log counts = 0 and metrics = NaN\n",
    "                    mlflow.log_metric(f\"val_{src}_label_0_count\", 0)\n",
    "                    mlflow.log_metric(f\"val_{src}_label_1_count\", 0)\n",
    "                    mlflow.log_metric(f\"val_{src}_pos_precision\", float(\"nan\"))\n",
    "                    mlflow.log_metric(f\"val_{src}_pos_recall\",    float(\"nan\"))\n",
    "                    mlflow.log_metric(f\"val_{src}_pos_f2\",        float(\"nan\"))\n",
    "                    continue\n",
    "\n",
    "                # label distribution\n",
    "                label_counts = {int(r[\"label_bin\"]): r[\"count\"]\n",
    "                                for r in seg.groupBy(\"label_bin\").count().collect()}\n",
    "\n",
    "                for lbl, cnt in label_counts.items():\n",
    "                    mlflow.log_metric(f\"val_{src}_label_{lbl}_count\", cnt)\n",
    "\n",
    "                # ---- confusion-matrix counts for positive class (label = 1) ----\n",
    "                # true positives: label=1, prediction=1\n",
    "                tp = seg.filter((col(\"label_bin\") == 1) & (col(\"final_prediction\") == 1)).count()\n",
    "                # false positives: label=0, prediction=1\n",
    "                fp = seg.filter((col(\"label_bin\") == 0) & (col(\"final_prediction\") == 1)).count()\n",
    "                # false negatives: label=1, prediction=0\n",
    "                fn = seg.filter((col(\"label_bin\") == 1) & (col(\"final_prediction\") == 0)).count()\n",
    "\n",
    "                # optional: true negatives if you care\n",
    "                # tn = seg.filter((col(\"label_bin\") == 0) & (col(\"final_prediction\") == 0)).count()\n",
    "\n",
    "                # ---- safe metric calculation ----\n",
    "                def safe_div(num, den):\n",
    "                    return float(num) / den if den > 0 else float(\"nan\")\n",
    "\n",
    "                pos_precision = safe_div(tp, tp + fp)  # P = TP / (TP + FP)\n",
    "                pos_recall    = safe_div(tp, tp + fn)  # R = TP / (TP + FN)\n",
    "\n",
    "                if math.isnan(pos_precision) or math.isnan(pos_recall):\n",
    "                    pos_f2 = float(\"nan\")\n",
    "                else:\n",
    "                    denom = (beta**2) * pos_precision + pos_recall\n",
    "                    pos_f2 = ((1 + beta**2) * pos_precision * pos_recall / denom) if denom > 0 else float(\"nan\")\n",
    "\n",
    "                mlflow.log_metric(f\"val_{src}_pos_precision\", pos_precision)\n",
    "                mlflow.log_metric(f\"val_{src}_pos_recall\",    pos_recall)\n",
    "                mlflow.log_metric(f\"val_{src}_pos_f2\",        pos_f2)\n",
    "\n",
    "            print(\"Logging model and metrics to MLflow...\")\n",
    "            signature = infer_signature(train_df, training_predictions)\n",
    "\n",
    "            mlflow.spark.log_model(\n",
    "                model,\n",
    "                MODEL_NAME,\n",
    "                input_example=train_df.limit(1).toPandas(),\n",
    "                signature=signature,\n",
    "                registered_model_name=\"flight_delay_classification_baseline\"\n",
    "            )\n",
    "\n",
    "            total_pos = validation_predictions.filter(col(\"label_bin\") == 1).count()\n",
    "            total_neg = validation_predictions.filter(col(\"label_bin\") == 0).count()\n",
    "\n",
    "            mlflow.log_metric(\"val_total_pos\", total_pos)\n",
    "            mlflow.log_metric(\"val_total_neg\", total_neg)\n",
    "            mlflow.log_metric(\"val_total_count\", total_pos + total_neg)\n",
    "\n",
    "            mlflow.log_metric(\"train_precision\", precision_t)\n",
    "            mlflow.log_metric(\"validation_precision\", precision_v)\n",
    "\n",
    "            mlflow.log_metric(\"train_recall\", recall_t)\n",
    "            mlflow.log_metric(\"validation_recall\", recall_v)\n",
    "\n",
    "            mlflow.log_metric(\"train_f2\", f2_t)\n",
    "            mlflow.log_metric(\"validation_f2\", f2_v)\n",
    "\n",
    "            mlflow.log_metric(\"train_pr_auc\", pr_auc_t)\n",
    "            mlflow.log_metric(\"validation_pr_auc\", pr_auc_v)\n",
    "\n",
    "            mlflow.log_param(\"max_depth\", max_depth)\n",
    "            mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "            mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "            mlflow.log_param(\"num_round\", num_round)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e3578f5-b8da-4eed-8077-1342eaf512b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "pos_prec_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_bin\",\n",
    "    predictionCol=\"final_prediction\",\n",
    "    metricName=\"precisionByLabel\"\n",
    ").setMetricLabel(1)\n",
    "\n",
    "pos_rec_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_bin\",\n",
    "    predictionCol=\"final_prediction\",\n",
    "    metricName=\"recallByLabel\"\n",
    ").setMetricLabel(1)\n",
    "\n",
    "pos_precision_v = pos_prec_eval.evaluate(validation_predictions)\n",
    "pos_recall_v    = pos_rec_eval.evaluate(validation_predictions)\n",
    "pos_f2_v        = f2_eval.evaluate(validation_predictions)\n",
    "\n",
    "print(\"validation_pos_precision:\", pos_precision_v)\n",
    "print(\"validation_pos_recall:\",    pos_recall_v)\n",
    "print(\"validation_pos_f2:\",        pos_f2_v)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d78ecd1-6e77-41ab-809c-4377c4a773dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(validation_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce106885-b098-44f5-b93f-5c409384d904",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "DELAY_THRESHOLD = 15.0\n",
    "\n",
    "validation_labeled = validation_df.withColumn(\n",
    "    \"label_bin\", (col(\"DEP_DELAY_NEW\") >= lit(DELAY_THRESHOLD)).cast(\"double\")\n",
    ")\n",
    "\n",
    "validation_labeled.groupBy(\"label_bin\").count().show()\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "259bd39a-37f2-44d4-a569-c2e3361fed9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "pos_prec_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_bin\",\n",
    "    predictionCol=\"final_prediction\",\n",
    "    metricName=\"precisionByLabel\"\n",
    ").setMetricLabel(1)\n",
    "\n",
    "pos_rec_eval = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_bin\",\n",
    "    predictionCol=\"final_prediction\",\n",
    "    metricName=\"recallByLabel\"\n",
    ").setMetricLabel(1)\n",
    "\n",
    "for src in [\"quantile_low\", \"quantile_high\", \"classifier\"]:\n",
    "    print(\"=== Source:\", src, \"===\")\n",
    "    seg = validation_predictions.filter(col(\"decision_source\") == src)\n",
    "    print(\"count:\", seg.count())\n",
    "    seg.groupBy(\"label_bin\").count().show()\n",
    "\n",
    "    print(\"pos_precision:\", pos_prec_eval.evaluate(seg))\n",
    "    print(\"pos_recall:\",    pos_rec_eval.evaluate(seg))\n",
    "    print(\"pos_F2:\",        f2_eval.evaluate(seg))\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01ca351a-258c-43eb-a7d4-454598d14388",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "experiment_name = \"/Shared/team_2_2/mlflow-2-stage-dev\"    # <-- change me\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "# Save all runs to CSV in DBFS\n",
    "runs.to_csv(\n",
    "    \"/dbfs/FileStore/mlflow_dev_runs_1.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Saved mlflow_runs.csv in /dbfs/FileStore/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79e68e20-7d5a-417b-b1b7-8c6274bd4845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab3b1719-5ed7-4e1a-80d4-44953fa7d3d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3915201981340937,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "(Daniel Clone) XGB_1yr_baseline_SO",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
