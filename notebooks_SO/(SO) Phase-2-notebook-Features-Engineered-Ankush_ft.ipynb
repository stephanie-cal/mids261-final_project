{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46f0190e-ca20-42f1-a87e-a3db6d8ecc04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "466c9b79-14bf-4db7-906c-23b1354bd52f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import mlflow\n",
    "print(mlflow.__version__)\n",
    "\n",
    "import os\n",
    "os.environ['PYSPARK_PIN_THREAD'] = 'false'\n",
    "spark.conf.set(\"spark.databricks.mlflow.trackMLlib.enabled\", \"true\")\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "# Define experiment name with proper Databricks path\n",
    "EXPERIMENT_NAME = \"/Shared/team_2_2/mlflow-baseline\"\n",
    "# Create the experiment if it doesn't exist\n",
    "try:\n",
    "    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if experiment is None:\n",
    "        experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "        print(f\"Created new experiment with ID: {experiment_id}\")\n",
    "    else:\n",
    "        print(f\"Using existing experiment: {experiment.name}\")\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "except Exception as e:\n",
    "    print(f\"Error with experiment setup: {e}\")\n",
    "    # Fallback to default experiment in workspace\n",
    "    mlflow.set_experiment(f\"/Users/{dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()}/default\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06fa16c1-a344-469e-aca4-26f972599b0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "688cfa43-b780-451f-b18a-a36522496d8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def checkpoint_dataset(dataset, file_path):\n",
    "    # Create base folder\n",
    "    section = \"2\"\n",
    "    number = \"2\"\n",
    "    base_folder = f\"dbfs:/student-groups/Group_{section}_{number}\"\n",
    "    dbutils.fs.mkdirs(base_folder)\n",
    "    # Create subfolders if file_path contains directories\n",
    "    full_path = f\"{base_folder}/{file_path}.parquet\"\n",
    "    subfolder = \"/\".join(full_path.split(\"/\")[:-1])\n",
    "    dbutils.fs.mkdirs(subfolder)\n",
    "    # Save dataset as a parquet file\n",
    "    dataset.write.mode(\"overwrite\").parquet(full_path)\n",
    "    print(f\"Checkpointed {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0db5928-9c77-4e1d-a2ac-f43858d4d211",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def checkpoint_dataset(dataset, file_path):\n",
    "    # Create folder\n",
    "    section = \"2\"\n",
    "    number = \"2\"\n",
    "    folder_path = f\"dbfs:/student-groups/Group_{section}_{number}\"\n",
    "    dbutils.fs.mkdirs(folder_path)\n",
    "    # Save df_weather as a parquet file\n",
    "    dataset.write.parquet(f\"{folder_path}/{file_path}.parquet\")\n",
    "    print(f\"Checkpointed {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "128ec4a2-9ea7-4229-b0f4-794a0f63cc30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "675168df-c888-46fb-bb01-1d47bac13b68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Airline Data    \n",
    "df_flights = spark.read.parquet(f\"dbfs:/mnt/mids-w261/datasets_final_project_2022/parquet_airlines_data_3m/\")\n",
    "print(df_flights.count())\n",
    "display(df_flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38767e31-d3f0-4741-a025-b53d950ddd4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Column analysis - Can remove later\n",
    "- OP_UNIQUE_CARRIER == OP_CARRIER_AIRLINE_ID == OP_CARRIER == OP_CARRIER_FL_NUM\n",
    "- TAIL_NUMBER --> License Plate Number\n",
    "- ORIGIN_AIRPORT_SEQ_ID == ORIGIN_CITY_MARKET_ID == ORIGIN == ORIGIN_CITY_NAME == ORIGIN_STATE_ABR == ORIGIN_STATE_FIPS (code for state) == ORIGIN_STATE_NM == ORIGIN_WAC (origin airport, world area code)\n",
    "- DEST_AIRPORT_ID == DEST_AIRPORT_SEQ_ID == DEST_CITY_MARKET_ID == DEST == DEST_CITY_NAME == DEST_STATE_ABR == DEST_STATE_FIPS == DEST_STATE_NAME == DEST_WAC\n",
    "- CRS_DEP_TIME -> Scheduled departure time in the computer reservation system\n",
    "---\n",
    "- DEP_TIME -> Actual Dept time\n",
    "- DEPT_DELAY -> difference in minutes between scheduled and actual departure time\n",
    "- DEPT_DELAY_NEW -> early flights are 0\n",
    "- DEP_DEL15\n",
    "- DEP_DELAY_GROUP\n",
    "- DEP_TIME_BLK\n",
    "- TAXI_OUT -> Taxi out time in minutes\n",
    "- WHEELS OFF\n",
    "- WHEELS ON - Time at landing (local time)\n",
    "- TAXI_IN\n",
    "- CRS ARR TIME - scheduled arrival time\n",
    "- ARR_TIME - actual arrival time\n",
    "- ARR_DELAY\n",
    "- ARR_DELAY_NEW\n",
    "- ARR_DEL15\n",
    "- ARR_DELAY_GROUP\n",
    "- ARR_TIME_BLK\n",
    "- CANCELLED, CANELLATION_CODE, DIVERTED\n",
    "- CRS_ELAPSED_TIME - scheduled flight time\n",
    "- ACTUAL_ELAPSED_TIME\n",
    "- AIR_TIME = flight time in minutes\n",
    "- FLIGHTS = Number of flights (Idk what this means)\n",
    "- DISTANCE\n",
    "- DISTANCE_GROUP (every 250 miles)\n",
    "- CARRIER_DELAY\n",
    "- WEATHER_DELAY\n",
    "- NAS_DELAY (National air system delay)\n",
    "- SECURITY_DELAY\n",
    "- LATE_AIRCRAFT_DELAY\n",
    "- FIRST_DEP_TIME - first gate departure time at origin airport (nulls see what to do with them)\n",
    "- TOTAL_ADD_GTIME - total ground time away from gate for gate return or cancelled flight\n",
    "- LONGEST_ADD_GTME - longest time away from gate for gate return or cancelled flight\n",
    "- A BUNCH OF DIVERTED AIRPORT COLUMNS (do some eda, they seem empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "924d73f8-797f-419e-a4c6-a2973ba7b1cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Things to keep in mind\n",
    "- Predict two hours before\n",
    "- Remove all the delay columns\n",
    "- Are we only predicting departure delays or arrival delays also? For example, the pilot misses the landing, and has to circle back for 20 minutes. Should we solve for that? I don't think we should."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d49ea99-57cc-4ba9-b438-7386aa04e939",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Preprocessing / Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c79c86e-1796-406c-a96d-43c0b244fbda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make a copy of the dataset\n",
    "df_flights = df_flights.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8efb6463-6f5c-4337-bb60-7a3d614940b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# combine date and scheduled departure time\n",
    "\n",
    "df_flights = df_flights.withColumn(\n",
    "    \"utc_timestamp\",\n",
    "    F.to_timestamp(\n",
    "        F.concat(\n",
    "            F.col(\"FL_DATE\"),\n",
    "            F.lit(\" \"),\n",
    "            F.lpad(F.col(\"CRS_DEP_TIME\").cast(\"string\"), 4, \"0\")\n",
    "        ),\n",
    "        \"yyyy-MM-dd HHmm\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29cf56e3-60e2-49f7-ad29-0d896e542254",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# impute null values for tail numbers\n",
    "#   - all replaced tail numbers will start with 'X' followed by a randomized 5 digit number\n",
    "\n",
    "df_flights = df_flights.withColumn(\n",
    "    \"TAIL_NUM\",\n",
    "    F.when(\n",
    "        F.col(\"TAIL_NUM\").isNull(),\n",
    "        F.concat(\n",
    "            F.lit(\"X\"),\n",
    "            (F.floor(F.rand() * 89999) + 10000).cast(\"string\")\n",
    "        )\n",
    "    ).otherwise(F.col(\"TAIL_NUM\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "772c5ce8-150f-4366-acb8-823a80ae2293",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6d6f9c3-47ea-4ff0-8ed4-67f891e00385",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = f\"dbfs:/student-groups/Group_2_2\"\n",
    "dataset_path = f\"{checkpoint_path}/3_month/raw_data/training_splits\"\n",
    "\n",
    "# Read datasets from checkpoint\n",
    "train_df = spark.read.parquet(f\"{dataset_path}/train.parquet\")\n",
    "validation_df = spark.read.parquet(f\"{dataset_path}/validation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb9ad4ff-0453-41cc-8c32-577b10bcdcdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "## CRS_DEP_TIME is local time so we can use this feature \n",
    "## But in order to use it, we have to convert it to minutes since midnight\n",
    "## Otherwise the timing will be off b/c it's not true UTC\n",
    "\n",
    "train_df = train_df.\\\n",
    "        withColumn(\"CRS_DEP_MINUTES\", (F.floor(F.col(\"CRS_DEP_TIME\") / 100) * 60 + (F.col(\"CRS_DEP_TIME\") % 100))).\\\n",
    "        drop(\"CRS_DEP_TIME\").\\\n",
    "        drop(\"CRS_ARR_TIME\")\n",
    "\n",
    "validation_df = validation_df.\\\n",
    "        withColumn(\"CRS_DEP_MINUTES\", (F.floor(F.col(\"CRS_DEP_TIME\") / 100) * 60 + (F.col(\"CRS_DEP_TIME\") % 100))).\\\n",
    "        drop(\"CRS_DEP_TIME\").\\\n",
    "        drop(\"CRS_ARR_TIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18b48fba-396a-4a0f-9280-78250938628d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Eng.\n",
    "\n",
    "#### Was the previous flight delayed? And by how much was the previous flight delayed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96047694-161f-431a-9fdf-f9a11b3618eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b88bc6f0-ba4d-4358-84c2-bf54aa9dfcd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df \\\n",
    "    .withColumn(\"prev_flight_delay_in_minutes\", F.lag(\"DEP_DELAY_NEW\", 1) \\\n",
    "        .over(Window.partitionBy(\"TAIL_NUM\") \\\n",
    "        .orderBy(\"utc_timestamp\"))) \\\n",
    "    .withColumn(\"prev_flight_delay_in_minutes\", F.when(F.col(\"prev_flight_delay_in_minutes\").isNull(), -1) \\\n",
    "        .otherwise(F.col(\"prev_flight_delay_in_minutes\"))) \\\n",
    "    .withColumn(\"prev_flight_delay\", F.when(F.col(\"prev_flight_delay_in_minutes\") > 15, 1) \\\n",
    "        .otherwise(F.lit(0)))\n",
    "    \n",
    "validation_df = validation_df \\\n",
    "    .withColumn(\"prev_flight_delay_in_minutes\", F.lag(\"DEP_DELAY_NEW\", 1) \\\n",
    "        .over(Window.partitionBy(\"TAIL_NUM\") \\\n",
    "        .orderBy(\"utc_timestamp\"))) \\\n",
    "    .withColumn(\"prev_flight_delay_in_minutes\", F.when(F.col(\"prev_flight_delay_in_minutes\").isNull(), -1) \\\n",
    "        .otherwise(F.col(\"prev_flight_delay_in_minutes\"))) \\\n",
    "    .withColumn(\"prev_flight_delay\", F.when(F.col(\"prev_flight_delay_in_minutes\") > 15, 1) \\\n",
    "        .otherwise(F.lit(0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f88cb621-66e4-424c-917a-85011399dd63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Number of delays before in the last 4 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c950b161-bad1-412a-b602-6d9f43a93574",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "useful_columns = [\n",
    "    \"QUARTER\",\n",
    "    \"MONTH\",\n",
    "    \"YEAR\",\n",
    "    \"DAY_OF_MONTH\",\n",
    "    \"DAY_OF_WEEK\",\n",
    "    \"OP_CARRIER\",\n",
    "    \"TAIL_NUM\",\n",
    "    \"ORIGIN_AIRPORT_SEQ_ID\",\n",
    "    \"DEST_AIRPORT_SEQ_ID\",\n",
    "    \"CRS_DEP_MINUTES\",\n",
    "    \"CRS_ELAPSED_TIME\",\n",
    "    \"DISTANCE\",\n",
    "    \"DEP_DELAY_NEW\",\n",
    "    \"utc_timestamp\",\n",
    "    \"prev_flight_delay_in_minutes\",\n",
    "    \"prev_flight_delay\",\n",
    "    \"origin_delays_4h\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2254a6a6-a88e-4a4c-a407-4ea08be698a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "window_4h = Window \\\n",
    "    .partitionBy(\"ORIGIN_AIRPORT_SEQ_ID\") \\\n",
    "    .orderBy(F.col(\"utc_timestamp\").cast(\"long\")) \\\n",
    "    .rangeBetween(-14400, -7200) # 4 hours to 2 hours before\n",
    "\n",
    "train_df = train_df \\\n",
    "    .withColumn(\"origin_delays_4h\", F.count(F.when(F.col(\"DEP_DELAY_NEW\") > 15, 1)) \\\n",
    "        .over(window_4h)\n",
    "    )\n",
    "validation_df = validation_df \\\n",
    "    .withColumn(\"origin_delays_4h\", F.count(F.when(F.col(\"DEP_DELAY_NEW\") > 15, 1)) \\\n",
    "        .over(window_4h)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79d9c263-ad93-4094-9f1d-45388954d17c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "baselines_columns = [\n",
    "    \"QUARTER\",\n",
    "    \"MONTH\",\n",
    "    \"YEAR\",\n",
    "    \"DAY_OF_MONTH\",\n",
    "    \"DAY_OF_WEEK\",\n",
    "    \"OP_CARRIER\",\n",
    "    \"TAIL_NUM\",\n",
    "    \"ORIGIN_AIRPORT_SEQ_ID\",\n",
    "    \"DEST_AIRPORT_SEQ_ID\",\n",
    "    \"CRS_DEP_MINUTES\",\n",
    "    \"CRS_ELAPSED_TIME\",\n",
    "    \"DISTANCE\",\n",
    "    \"DEP_DELAY_NEW\",\n",
    "    # \"utc_timestamp\",\n",
    "    \"prev_flight_delay_in_minutes\",\n",
    "    \"prev_flight_delay\",\n",
    "    \"origin_delays_4h\"\n",
    "]\n",
    "\n",
    "\n",
    "train_df = train_df.filter(F.col(\"DEP_DELAY_NEW\").isNotNull()).select(baselines_columns)\n",
    "validation_df = validation_df.filter(F.col(\"DEP_DELAY_NEW\").isNotNull()).select(baselines_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7ff4688-854e-4a7f-9429-b74fdc925f0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "# Categorical encoding\n",
    "carrier_indexer = StringIndexer(inputCol=\"OP_CARRIER\", outputCol=\"carrier_idx\", handleInvalid=\"keep\")\n",
    "origin_indexer = StringIndexer(inputCol=\"ORIGIN_AIRPORT_SEQ_ID\", outputCol=\"origin_idx\", handleInvalid=\"keep\")\n",
    "dest_indexer = StringIndexer(inputCol=\"DEST_AIRPORT_SEQ_ID\", outputCol=\"dest_idx\", handleInvalid=\"keep\")\n",
    "tail_num_indexer = StringIndexer(inputCol=\"TAIL_NUM\", outputCol=\"tail_num_idx\", handleInvalid=\"keep\")\n",
    "\n",
    "carrier_encoder = OneHotEncoder(inputCol=\"carrier_idx\", outputCol=\"carrier_vec\")\n",
    "origin_encoder = OneHotEncoder(inputCol=\"origin_idx\", outputCol=\"origin_vec\")\n",
    "dest_encoder = OneHotEncoder(inputCol=\"dest_idx\", outputCol=\"dest_vec\")\n",
    "tail_num_encoder = OneHotEncoder(inputCol=\"tail_num_idx\", outputCol=\"tail_num_vec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdde39db-852d-4ce5-882d-a3f7f7cf3f86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Assemble all features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"QUARTER\",\n",
    "        \"MONTH\", \n",
    "        \"YEAR\",\n",
    "        \"DAY_OF_MONTH\",\n",
    "        \"DAY_OF_WEEK\",\n",
    "        \"carrier_vec\",\n",
    "        \"origin_vec\",\n",
    "        \"dest_vec\",\n",
    "        \"tail_num_vec\",\n",
    "        \"CRS_DEP_MINUTES\",\n",
    "        \"CRS_ELAPSED_TIME\",\n",
    "        \"DISTANCE\",\n",
    "        \"prev_flight_delay_in_minutes\",\n",
    "        \"prev_flight_delay\",\n",
    "        \"origin_delays_4h\"\n",
    "    ],\n",
    "    outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2261bf73-37b9-4449-8bd0-445fd78d1659",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# linear regression baseline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "mlflow.spark.autolog()\n",
    "with mlflow.start_run(run_name=\"RF - origin airport delays\"):\n",
    "    MODEL_NAME = \"RF_ORIGIN_DELAYS\"\n",
    "\n",
    "    linear_reg = LinearRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"DEP_DELAY_NEW\",\n",
    "        # Linear Regression has different parameters than Random Forest\n",
    "        maxIter=10, \n",
    "        regParam=0.3\n",
    "    )\n",
    "    # rf = RandomForestRegressor(\n",
    "    #     featuresCol=\"features\",  \n",
    "    #     labelCol=\"DEP_DELAY_NEW\",   \n",
    "    #     numTrees=20,\n",
    "    #     maxDepth=10\n",
    "    # )\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(stages=[\n",
    "        carrier_indexer, origin_indexer, dest_indexer, tail_num_indexer,\n",
    "        carrier_encoder, origin_encoder, dest_encoder, tail_num_encoder,\n",
    "        assembler,\n",
    "        linear_reg\n",
    "        # rf\n",
    "    ])\n",
    "\n",
    "    model = pipeline.fit(train_df)\n",
    "    training_predictions = model.transform(train_df)\n",
    "    validation_predictions = model.transform(validation_df)\n",
    "\n",
    "    mae_evaluator = RegressionEvaluator(\n",
    "        labelCol=\"DEP_DELAY_NEW\",      \n",
    "        predictionCol=\"prediction\", \n",
    "        metricName=\"mae\"           \n",
    "    )\n",
    "\n",
    "    rmse_evaluator = RegressionEvaluator(\n",
    "        labelCol=\"DEP_DELAY_NEW\",      \n",
    "        predictionCol=\"prediction\", \n",
    "        metricName=\"rmse\"\n",
    "    )\n",
    "\n",
    "    # Calculate MAE\n",
    "    mae_t = mae_evaluator.evaluate(training_predictions)\n",
    "    mae_v = mae_evaluator.evaluate(validation_predictions)\n",
    "    # Calculate RMSE\n",
    "    rmse_t = rmse_evaluator.evaluate(training_predictions)\n",
    "    rmse_v = rmse_evaluator.evaluate(validation_predictions)\n",
    "\n",
    "    signature = infer_signature(train_df, training_predictions)\n",
    "\n",
    "    mlflow.spark.log_model(\n",
    "        model, \n",
    "        MODEL_NAME,\n",
    "        input_example=train_df.limit(1).toPandas(),\n",
    "        signature=signature,\n",
    "        registered_model_name=\"flight_delay_prediction_baseline\"\n",
    "        )\n",
    "\n",
    "    mlflow.log_metric(\"train_mae\", mae_t)\n",
    "    mlflow.log_metric(\"validation_mae\", mae_v)\n",
    "    mlflow.log_metric(\"train_rmse\", rmse_t)\n",
    "    mlflow.log_metric(\"validation_rmse\", rmse_v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da4f00cf-6cf1-4fd8-8978-eeffabd98c37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Checkpoint results to MLflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca6e576c-33d9-412d-a2ea-f0bc9035128c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Develop and Run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce98ccb9-f492-48d3-940c-4c237eaf83e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86c39b08-da9a-4430-85af-61cb665b1965",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Save metrics, pipeline, any other steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc20216a-d892-45d1-8042-3f13d3f2496b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81d8aae1-c078-4cad-9e1c-162d66cf7434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Feature Engineering Ideas\n",
    "- Previous flight delay in minutes for the aircraft [DONE] - this added value to the linear regression model!\n",
    "- Number of delayed flights from 4 hours (DONE)\n",
    "- Number of delays in the route in the last 30 days\n",
    "- Time between landing and scheduled current flight\n",
    "- Airport + utc time type of delay - Ohare at 6PM is always late\n",
    "- Number of delayed flights in departure and arrival location (total or 4 hours before, 6 hours before, etc.)\n",
    "- Average delay time by airport\n",
    "- Average taxi out time by airport/flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e732e7e-3b42-4296-85e1-5c3d78506174",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6978085643709185,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "(SO) Phase-2-notebook-Features-Engineered-Ankush_ft",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
